{"cells":[{"cell_type":"markdown","id":"cd16b39b","metadata":{"id":"cd16b39b"},"source":["---\n","# **LAB 9 - CUDA in Python**\n","---"]},{"cell_type":"markdown","metadata":{"id":"-_i3qX0HhLrV"},"source":["# ‚ñ∂Ô∏è CUDA setup"],"id":"-_i3qX0HhLrV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZS1v474hLrW"},"outputs":[],"source":["!nvcc --version"],"id":"JZS1v474hLrW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWZ7N-4OhLrW"},"outputs":[],"source":["!nvidia-smi"],"id":"TWZ7N-4OhLrW"},{"cell_type":"code","source":["!pip install numba-cuda==0.4.0"],"metadata":{"id":"xSoLaRWchLrX"},"execution_count":null,"outputs":[],"id":"xSoLaRWchLrX"},{"cell_type":"code","source":["from numba import config\n","config.CUDA_ENABLE_PYNVJITLINK = 1"],"metadata":{"id":"iTq5M1SfhLrX"},"execution_count":null,"outputs":[],"id":"iTq5M1SfhLrX"},{"cell_type":"markdown","id":"32aab92c","metadata":{"id":"32aab92c"},"source":["# üêç Numba for CPU"]},{"cell_type":"markdown","id":"ec33a76a","metadata":{"id":"ec33a76a"},"source":["Monte Carlo Method to determine Pi.\n","\n","- Confirm the compiled version is behaving the same as the uncompiled version.\n","- Benchmark the uncompiled version.\n","- Benchmark the compiled version.\n","\n","Note: Numba saves the original Python implementation of the function in the **.py_func** attribute, so we can call the original Python code to make sure we get the same answer"]},{"cell_type":"code","execution_count":null,"id":"043af3e4","metadata":{"id":"043af3e4"},"outputs":[],"source":["from numba import jit\n","from numpy import testing\n","import random\n","\n","# Use the Numba compiler to compile this function\n","@jit(nopython=True)\n","def monte_carlo_pi(nsamples):\n","    acc = 0\n","    for i in range(nsamples):\n","        x = random.random()\n","        y = random.random()\n","        if (x**2 + y**2) < 1.0:\n","            acc += 1\n","    return 4.0 * acc / nsamples\n","\n","# Run the function\n","nsamples = 1000000\n","\n","# We will use numpy's `testing` library to confirm compiled and uncompiled versions run the same\n","testing.assert_almost_equal(monte_carlo_pi(nsamples), monte_carlo_pi.py_func(nsamples), decimal=2)"]},{"cell_type":"code","execution_count":null,"id":"da1e673b","metadata":{"id":"da1e673b"},"outputs":[],"source":["%timeit monte_carlo_pi(nsamples)"]},{"cell_type":"code","execution_count":null,"id":"7e2b5802","metadata":{"id":"7e2b5802"},"outputs":[],"source":["%timeit monte_carlo_pi.py_func(nsamples)"]},{"cell_type":"code","execution_count":null,"id":"1de59c01","metadata":{"id":"1de59c01"},"outputs":[],"source":["import numpy as np\n","\n","def my_sum(x, y):\n","    return x + y\n","\n","np_my_sum = np.frompyfunc(my_sum, 2, 1) # create ufunc\n","print(type(my_sum), type(np_my_sum))    # check types\n","print(my_sum(1, 1), np_my_sum(1, 1))    # check if the same"]},{"cell_type":"markdown","id":"7fde79c5","metadata":{"id":"7fde79c5"},"source":["### Define a ufunc using numba's vectorize..."]},{"cell_type":"code","execution_count":null,"id":"85d37cbc","metadata":{"id":"85d37cbc"},"outputs":[],"source":["from numba import vectorize\n","import numpy as np\n","\n","# Define a ufunc using numba's vectorize\n","@vectorize(['float64(float64, float64)'], target='cpu')\n","def multiply(x, y):\n","\treturn x * y\n","\n","# Test the ufunc\n","a = np.array([1.0, 2.0, 3.0, 4.0])\n","b = np.array([10.0, 20.0, 30.0, 40.0])\n","\n","result = multiply(a, b)\n","print(result)"]},{"cell_type":"code","execution_count":null,"id":"a3fedab5","metadata":{"id":"a3fedab5"},"outputs":[],"source":["import numpy as np\n","from numba import vectorize, int64, float32, float64\n","\n","# create default ufunc with datatypes conversion\n","@vectorize([int64(int64,int64), float32(float32,float32), float64(float64,float64)])\n","def numba_dtype_sum(x, y):\n","    return x + y\n","\n","print(type(numba_dtype_sum))  # check type\n","print(numba_dtype_sum(1, 1))  # check on scalars\n","print(numba_dtype_sum(np.ones(4), np.ones(4))) # check int arrays\n","print(numba_dtype_sum(np.random.rand(4), np.random.rand(4))) # check float arrays"]},{"cell_type":"markdown","id":"07e50f9d","metadata":{"id":"07e50f9d"},"source":["### Numba can parallelize loops using **parallel=True**..."]},{"cell_type":"code","execution_count":null,"id":"5707b316","metadata":{"id":"5707b316"},"outputs":[],"source":["from numba import njit, prange\n","import numpy as np\n","\n","@njit(parallel=True)\n","def parallel_sum(arr):\n","    total = 0\n","    for i in prange(len(arr)):  # Parallel execution\n","        total += arr[i]\n","    return total\n","\n","arr = np.random.rand(1000000)\n","print(parallel_sum(arr))"]},{"cell_type":"code","execution_count":null,"id":"4c806e08","metadata":{"id":"4c806e08"},"outputs":[],"source":["%timeit parallel_sum(arr)"]},{"cell_type":"code","execution_count":null,"id":"e8a510da","metadata":{"id":"e8a510da"},"outputs":[],"source":["%timeit arr.sum()"]},{"cell_type":"markdown","id":"4ac7368d","metadata":{"id":"4ac7368d"},"source":["### Type Specialization: Numba automatically specializes functions based on input types..."]},{"cell_type":"code","execution_count":null,"id":"27469f21","metadata":{"id":"27469f21"},"outputs":[],"source":["from numba import jit\n","\n","@jit(nopython=True)\n","def multiply(x, y):\n","   return x * y\n","\n","print(multiply(3, 4))      # Optimized for integers\n","print(multiply(3.5, 4.2))  # Optimized for floats\n"]},{"cell_type":"markdown","id":"c1807bca","metadata":{"id":"c1807bca"},"source":["### Execution time: compilation + execution..."]},{"cell_type":"code","execution_count":null,"id":"fd478be6","metadata":{"id":"fd478be6"},"outputs":[],"source":["from numba import jit\n","import numpy as np\n","import time\n","\n","\n","@jit(nopython=True)\n","def go_fast(a): # Function is compiled and runs in machine code\n","\ttrace = 0.0\n","\tfor i in range(a.shape[0]):\n","\t\ttrace += np.tanh(a[i])\n","\treturn trace\n","\n","x = np.arange(100000)\n","\n","# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n","start = time.time()\n","go_fast(x)\n","end = time.time()\n","print(\"Elapsed (with compilation) = %s\" % (end - start))\n","\n","# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n","start = time.time()\n","go_fast(x)\n","end = time.time()\n","print(\"Elapsed (after compilation) = %s\" % (end - start))\n"]},{"cell_type":"markdown","id":"654daecb","metadata":{"id":"654daecb"},"source":["# üêç Numba for GPU"]},{"cell_type":"markdown","id":"cb659914","metadata":{"id":"cb659914"},"source":["### Numba check and device detect..."]},{"cell_type":"code","execution_count":null,"id":"208066f9","metadata":{"id":"208066f9"},"outputs":[],"source":["import numba\n","from numba import cuda\n","import numpy as np\n","\n","print(f'NumPy version: {np.__version__}')\n","print(f'Numba version: {numba.__version__}')\n","print(f'CUDA driver version: {cuda.driver.get_version()}')\n","print(f'CUDA runtime version: {cuda.runtime.get_version()}')\n","\n","# device detect\n","cuda.detect()"]},{"cell_type":"markdown","id":"655752a3","metadata":{"id":"655752a3"},"source":["### Kernel configuration and definition..."]},{"cell_type":"code","execution_count":null,"id":"1dfc80c0","metadata":{"id":"1dfc80c0"},"outputs":[],"source":["import numpy as np\n","\n","# Define the kernel function\n","@cuda.jit\n","def increment_by_one(an_array):\n","\t# Thread id in a 1D block\n","\ttx = cuda.threadIdx.x\n","\t# Block id in a 1D grid\n","\tbx = cuda.blockIdx.x\n","\t# Block width, i.e. number of threads per block\n","\tbw = cuda.blockDim.x\n","\t# Compute flattened index inside the array\n","\tpos = tx + bx * bw\n","\tif pos < an_array.size:  # Check array boundaries\n","\t\tan_array[pos] += 1"]},{"cell_type":"code","execution_count":null,"id":"3e463d8b","metadata":{"id":"3e463d8b"},"outputs":[],"source":["# Create a random array\n","an_array = np.random.rand(1000000).astype(np.float32)\n","# Allocate device memory\n","d_an_array = cuda.to_device(an_array)\n","# Define the number of threads per block\n","threads_per_block = 256\n","# Define the number of blocks in the grid\n","blocks_per_grid = (an_array.size + (threads_per_block - 1)) // threads_per_block\n","# Launch the kernel\n","increment_by_one[blocks_per_grid, threads_per_block](d_an_array)\n","# Copy the result back to host\n","an_array = d_an_array.copy_to_host()\n","# Check the result\n","print(an_array[:10])  # Print first 10 elements to verify\n","\n"]},{"cell_type":"markdown","id":"a82ccc30","metadata":{"id":"a82ccc30"},"source":["# üêç Mat multiplication"]},{"cell_type":"markdown","id":"3aaee970","metadata":{"id":"3aaee970"},"source":["Multiplication..."]},{"cell_type":"code","execution_count":null,"id":"7e0ca18a","metadata":{"id":"7e0ca18a"},"outputs":[],"source":["from numba.types import float32\n","\n","BLOCK_SIZE = 32\n","\n","# kernel matrix multiplication\n","@cuda.jit\n","def matmul_gpu(A, B, C):\n","\t\"\"\"Perform square matrix multiplication of C = A * B.\"\"\"\n","\ti, j = cuda.grid(2)\n","\tif i < C.shape[0] and j < C.shape[1]:\n","\t\ttmp = 0.\n","\t\tfor k in range(A.shape[1]):\n","\t\t\ttmp += A[i, k] * B[k, j]\n","\t\tC[i, j] = tmp\n","\n","# kernel matrix multiplication with shared memory\n","@cuda.jit\n","def fast_matmul(A, B, C):\n","\t\"\"\"Perform square matrix multiplication of C = A * B using shared memory.\"\"\"\n","\t# Define an array in the shared memory\n","\tsA = cuda.shared.array(shape=(BLOCK_SIZE, BLOCK_SIZE), dtype=float32)\n","\tsB = cuda.shared.array(shape=(BLOCK_SIZE, BLOCK_SIZE), dtype=float32)\n","\n","\t# Calculate thread indices\n","\tx, y = cuda.grid(2)\n","\ttx = cuda.threadIdx.x\n","\tty = cuda.threadIdx.y\n","\tbpg = cuda.gridDim.x\n","\ttmp = float32(0.)\n","\n","\t# Each thread computes one element in the result matrix.\n","\tfor i in range(bpg):\n","\t\tsA[ty, tx] = 0\n","\t\tsB[ty, tx] = 0\n","\t\tif y < A.shape[0] and (tx + i * BLOCK_SIZE) < A.shape[1]:\n","\t\t\tsA[ty, tx] = A[y, tx + i * BLOCK_SIZE]\n","\t\tif x < B.shape[1] and (ty + i * BLOCK_SIZE) < B.shape[0]:\n","\t\t\tsB[ty, tx] = B[ty + i * BLOCK_SIZE, x]\n","\n","\t\t# Synchronize threads to ensure all data is loaded into shared memory\n","\t\tcuda.syncthreads()\n","\n","\t\t# Each thread computes one element in the result matrix.\n","\t\tfor j in range(BLOCK_SIZE):\n","\t\t\ttmp += sA[ty, j] * sB[j, tx]\n","\n","\t\t# Wait until all threads finish computing\n","\t\tcuda.syncthreads()\n","\n","\t# Write the result to global memory\n","\tif y < C.shape[0] and x < C.shape[1]:\n","\t\tC[y, x] = tmp"]},{"cell_type":"code","execution_count":null,"id":"cf3d1e4f","metadata":{"id":"cf3d1e4f"},"outputs":[],"source":["import time\n","import numpy as np\n","\n","# generate random vals\n","np.random.seed(42)\n","SIZE = 1024*8\n","A = np.ones((SIZE,SIZE)).astype('float32')  # mat 1\n","B = np.ones((SIZE,SIZE)).astype('float32')  # mat 2\n","#C = np.zeros((SIZE,SIZE)).astype('float32')                       # mat where we store answer\n","\n","# transfer data to device\n","d_A = cuda.to_device(A) # Copy of A on the device\n","d_B = cuda.to_device(B) # Copy of B on the device\n","d_C = cuda.device_array_like(A) # malloc on the device\n","\n","# Define the number of threads in each block\n","block = (32, 32)  # each block will contain 32x32 threads, typically 128 - 512 threads/block\n","grid_x = int(np.ceil(A.shape[0] / block[0]))\n","grid_y = int(np.ceil(A.shape[1] / block[1]))\n","grid = (grid_x, grid_y)  # we calculate the gridsize (number of blocks) from array\n","print(f\"Matrix size: {SIZE}x{SIZE}\")\n","print(f\"Grid size: {grid_x}x{grid_y}\")\n","print(f\"Block size: {block[0]}x{block[1]}\")"]},{"cell_type":"code","execution_count":null,"id":"5330e195","metadata":{"id":"5330e195"},"outputs":[],"source":["# execution of the kernel matmul_gpu\n","start = time.time()\n","matmul_gpu[grid, block](d_A, d_B, d_C)\n","# host and device sync\n","cuda.synchronize()\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))"]},{"cell_type":"code","execution_count":null,"id":"03e2768d","metadata":{"id":"03e2768d"},"outputs":[],"source":["# execution of the kernel fast_matmul\n","start = time.time()\n","fast_matmul[grid, block](d_A, d_B, d_C)\n","# host and device sync\n","cuda.synchronize()\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))"]},{"cell_type":"code","execution_count":null,"id":"d3a1d5f1","metadata":{"id":"d3a1d5f1"},"outputs":[],"source":["# using numpy function\n","start = time.time()\n","C = np.matmul(A, B)\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))"]},{"cell_type":"code","execution_count":null,"id":"025f0275","metadata":{"id":"025f0275"},"outputs":[],"source":["import torch\n","\n","# the first multiplication here is significantly slower\n","m1 = torch.from_numpy(A).cuda()\n","m2 = torch.from_numpy(B).cuda()\n","c = torch.zeros((m1.shape[0], m2.shape[1]), dtype=torch.float32).cuda()\n","\n","start = time.time()\n","torch.matmul(m1, m2, out=c)\n","torch.cuda.synchronize()\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))"]},{"cell_type":"markdown","id":"67a5faae","metadata":{"id":"67a5faae"},"source":["# üêç Convolution 2D"]},{"cell_type":"markdown","id":"0f3a5ab3","metadata":{"id":"0f3a5ab3"},"source":["Parallel reduce..."]},{"cell_type":"code","execution_count":null,"id":"71c61c3b","metadata":{"id":"71c61c3b"},"outputs":[],"source":["import numpy as np\n","from numba import cuda\n","from numba.types import int32\n","\n","SHARED_DIM = 1024\n","\n","@cuda.jit\n","def reduce(data):\n","\ttid = cuda.threadIdx.x\n","\tsize = len(data)\n","\tif tid < size:\n","\t\ti = cuda.grid(1)\n","\n","\t\t# Declare an array in shared memory\n","\t\tshr = cuda.shared.array(SHARED_DIM, int32)\n","\t\tshr[tid] = data[i]\n","\n","\t\t# Ensure writes to shared memory are visible\n","\t\t# to all threads before reducing\n","\t\tcuda.syncthreads()\n","\n","\t\ts = 1\n","\t\twhile s < cuda.blockDim.x:\n","\t\t\tif tid % (2 * s) == 0:\n","\t\t\t\t\t# Stride by `s` and add\n","\t\t\t\t\tshr[tid] += shr[tid + s]\n","\t\t\ts *= 2\n","\t\t\tcuda.syncthreads()\n","\n","\t\t# After the loop, the zeroth  element contains the sum\n","\t\tif tid == 0:\n","\t\t\tdata[tid] = shr[tid]"]},{"cell_type":"code","execution_count":null,"id":"12869042","metadata":{"id":"12869042"},"outputs":[],"source":["# generate data\n","nelem = SHARED_DIM\n","a = cuda.to_device(np.arange(nelem, dtype=np.int32))\n","print(\"Number of elements: \", len(a))\n","\n","# kernel\n","reduce[1, nelem](a)\n","\n","# copy to host\n","b = a.copy_to_host()\n","\n","print(b[0])  # 523776\n","print(sum(np.arange(nelem)))  # 523776"]},{"cell_type":"markdown","id":"682d5a0e","metadata":{"id":"682d5a0e"},"source":["‚Ü© TODO: Convolution 2D..."]},{"cell_type":"code","execution_count":null,"id":"e20a19a5","metadata":{"id":"e20a19a5"},"outputs":[],"source":["import numpy as np\n","from numba import cuda\n","\n","# Define kernel size\n","KERNEL_SIZE = 3\n","BLOCK_SIZE = 16\n","TILE = (BLOCK_SIZE + KERNEL_SIZE - 1, BLOCK_SIZE + KERNEL_SIZE - 1)\n","\n","@cuda.jit\n","def conv2d_kernel(image, kernel, output):\n","\t# TODO: Implement the kernel function\n"]},{"cell_type":"code","execution_count":null,"id":"bec79011","metadata":{"id":"bec79011"},"outputs":[],"source":["# Test the kernel\n","image = np.random.rand(8*1024, 8*1024).astype(np.float32)  # Example image\n","kernel = np.random.rand(KERNEL_SIZE, KERNEL_SIZE).astype(np.float32)  # Example Gaussian Blur kernel\n","print('image.shape: ',image.shape)\n","print('kernel.shape:', kernel.shape)\n","\n","# copy data H2D\n","d_image = cuda.to_device(image)\n","d_kernel = cuda.to_device(kernel)\n","d_output = cuda.device_array(image.shape, dtype=np.float32)\n","\n","# grdi and block dim\n","block_dim = (BLOCK_SIZE, BLOCK_SIZE)\n","grid_dim = (image.shape[0] // BLOCK_SIZE, image.shape[1] // BLOCK_SIZE)\n","\n","# kernel\n","start = time.time()\n","conv2d_kernel[grid_dim, block_dim](d_image, d_kernel, d_output)\n","cuda.synchronize()\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))\n","output = d_output.copy_to_host()\n","print('output.shape:', output.shape)"]},{"cell_type":"code","execution_count":null,"id":"edf133f6","metadata":{"id":"edf133f6"},"outputs":[],"source":["from scipy import signal\n","\n","start = time.time()\n","grad = signal.convolve2d(image, kernel)\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))"]},{"cell_type":"markdown","id":"acef8f2e","metadata":{"id":"acef8f2e"},"source":["# üêç Atomic functions"]},{"cell_type":"code","execution_count":null,"id":"4b7459ab","metadata":{"id":"4b7459ab"},"outputs":[],"source":["import numpy as np\n","from numba import cuda\n","\n","@cuda.jit\n","def find_max(result, values):\n","\t\"\"\"Find the maximum value in values and store in result[0]\"\"\"\n","\ttid = cuda.threadIdx.x\n","\tbid = cuda.blockIdx.x\n","\tbdim = cuda.blockDim.x\n","\ti = (bid * bdim) + tid\n","\tcuda.atomic.max(result, 0, values[i])\n","\n","#### RUNNING THE KERNEL ####\n","arr = np.random.rand(1024*1024).astype(np.float32)  # Example array\n","d_arr = cuda.to_device(arr)  # Copy to device\n","result = np.zeros(1, dtype=np.float64)\n","d_result = cuda.to_device(result)  # Copy to device\n","find_max[1024,1024](d_result, d_arr)\n","print(d_result[0]) # Found using cuda.atomic.max\n","print(max(arr))  # Print max(arr) for comparison (should be equal!)"]},{"cell_type":"markdown","id":"fab59d61","metadata":{"id":"fab59d61"},"source":["Write an Accelerated Histogramming Kernel:\n","\n","For this assessment, you will create an accelerated histogramming kernel. This will take an array of input data, a range, and a number of bins, and count how many of the input data elements land in each bin"]},{"cell_type":"code","execution_count":null,"id":"828f1baf","metadata":{"id":"828f1baf"},"outputs":[],"source":["def cpu_histogram(x, xmin, xmax, histogram_out):\n","\t'''Increment bin counts in histogram_out, given histogram range [xmin, xmax).'''\n","\t# Note that we don't have to pass in nbins explicitly, because the size of histogram_out determines it\n","\tnbins = histogram_out.shape[0]\n","\tbin_width = (xmax - xmin) / nbins\n","\n","\t# This is a very slow way to do this with NumPy, but looks similar to what you will do on the GPU\n","\tfor element in x:\n","\t\tbin_number = np.int32((element - xmin)/bin_width)\n","\t\tif bin_number >= 0 and bin_number < histogram_out.shape[0]:\n","\t\t\t# only increment if in range\n","\t\t\thistogram_out[bin_number] += 1"]},{"cell_type":"code","execution_count":null,"id":"13f75909","metadata":{"id":"13f75909"},"outputs":[],"source":["x = np.random.normal(size=10000, loc=0, scale=1).astype(np.float32)\n","xmin = np.float32(-4.0)\n","xmax = np.float32(4.0)\n","histogram_out = np.zeros(shape=10, dtype=np.int32)\n","\n","cpu_histogram(x, xmin, xmax, histogram_out)\n","\n","histogram_out"]},{"cell_type":"markdown","metadata":{"id":"A1Ibo9v6oA3_"},"source":["‚Ü© TODO: Convolution 2D..."],"id":"A1Ibo9v6oA3_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddTpDuVZoEIK"},"outputs":[],"source":["@cuda.jit\n","def cuda_histogram(x, xmin, xmax, histogram_out):\n","\n","\t# TODO"],"id":"ddTpDuVZoEIK"},{"cell_type":"code","execution_count":null,"id":"07f1a348","metadata":{"id":"07f1a348"},"outputs":[],"source":["d_x = cuda.to_device(x)\n","d_histogram_out = cuda.to_device(np.zeros(shape=10, dtype=np.int32))\n","\n","blocks = 128\n","threads_per_block = 64\n","start = time.time()\n","cuda_histogram[blocks, threads_per_block](d_x, xmin, xmax, d_histogram_out)\n","\n","histogram_out = d_histogram_out.copy_to_host()\n","print(histogram_out)  # Print histogram\n","print(histogram_out.sum())  # Print sum of histogram\n","print(histogram_out.sum() == x.shape[0])  # Check if sum of histogram equals number of elements in x"]},{"cell_type":"code","execution_count":null,"id":"9701607b","metadata":{"id":"9701607b"},"outputs":[],"source":["# Define host array\n","threads_per_block = 256\n","blocks_per_grid = 32 * 40\n","a = np.ones(10_000_000, dtype=np.float32)\n","print(f\"Old sum: {a.sum():.2f}\")"]},{"cell_type":"markdown","id":"51f4a340","metadata":{"id":"51f4a340"},"source":["# üêç Streams"]},{"cell_type":"code","execution_count":null,"id":"1060a35c","metadata":{"id":"1060a35c"},"outputs":[],"source":["# Numba CUDA Stream Semantics\n","@cuda.jit\n","def partial_reduce(array, partial_reduction):\n","    i_start = cuda.grid(1)\n","    threads_per_grid = cuda.blockDim.x * cuda.gridDim.x\n","    s_thread = 0.0\n","    for i_arr in range(i_start, array.size, threads_per_grid):\n","        s_thread += array[i_arr]\n","\n","    s_block = cuda.shared.array((threads_per_block,), numba.float32)\n","    tid = cuda.threadIdx.x\n","    s_block[tid] = s_thread\n","    cuda.syncthreads()\n","\n","    i = cuda.blockDim.x // 2\n","    while (i > 0):\n","        if (tid < i):\n","            s_block[tid] += s_block[tid + i]\n","        cuda.syncthreads()\n","        i //= 2\n","\n","    if tid == 0:\n","        partial_reduction[cuda.blockIdx.x] = s_block[0]\n","\n","@cuda.jit\n","def single_thread_sum(partial_reduction, sum):\n","\tsum[0] = 0.0\n","\tfor element in partial_reduction:\n","\t\tsum[0] += element\n","\n","@cuda.jit\n","def divide_by(array, val_array):\n","\ti_start = cuda.grid(1)\n","\tthreads_per_grid = cuda.gridsize(1)\n","\tfor i in range(i_start, array.size, threads_per_grid):\n","\t\tarray[i] /= val_array[0]\n","\n","# Pin memory\n","with cuda.pinned(a):\n","\t# Create a CUDA stream\n","\tstream = cuda.stream()\n","\n","\t# Array copy to device and creation in the device\n","\tdev_a = cuda.to_device(a, stream=stream)\n","\tdev_a_reduce = cuda.device_array((blocks_per_grid,), dtype=dev_a.dtype, stream=stream)\n","\tdev_a_sum = cuda.device_array((1,), dtype=dev_a.dtype, stream=stream)\n","\n","\t# configuration, and it comes after the block dimension (`threads_per_block`)\n","\tpartial_reduce[blocks_per_grid, threads_per_block, stream](dev_a, dev_a_reduce)\n","\tsingle_thread_sum[1, 1, stream](dev_a_reduce, dev_a_sum)\n","\tdivide_by[blocks_per_grid, threads_per_block, stream](dev_a, dev_a_sum)\n","\n","\t# Array copy to host: like the copy to device, when a stream is passed, the copy\n","\t# is asynchronous. Note: the printed output will probably be nonsensical since\n","\t# the write has not been synchronized yet.\n","\tdev_a.copy_to_host(a, stream=stream)\n","\n","# Whenever we want to ensure that all operations in a stream are finished from\n","# the point of view of the host, we call:\n","stream.synchronize()\n","\n","# After that call, we can be sure that `a` has been overwritten with its normalized version\n","print(f\"New sum: {a.sum():.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"5UgcACiqoWXG"},"source":["‚Ü© TODO: Convolution 2D..."],"id":"5UgcACiqoWXG"},{"cell_type":"code","execution_count":null,"id":"76aeee6e","metadata":{"id":"76aeee6e"},"outputs":[],"source":["# Multiple streams\n","from time import perf_counter\n","\n","N_streams = 10\n","\n","# Create base arrays\n","arrays = [i * np.ones(10_000_000, dtype=np.float32) for i in range(1, N_streams + 1)]\n","\n","for i, arr in enumerate(arrays):\n","\tprint(f\"sum array {i}: {arr.sum():12.2f}\")\n","\n"," # TODO"]},{"cell_type":"markdown","id":"1ddb94a0","metadata":{"id":"1ddb94a0"},"source":["# üêç Pseudo-random generator"]},{"cell_type":"code","execution_count":null,"id":"05b68138","metadata":{"id":"05b68138"},"outputs":[],"source":["from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n","\n","@cuda.jit\n","def compute_pi(rng_states, iterations, out):\n","\t\"\"\"Find the maximum value in values and store in result[0]\"\"\"\n","\ttid = cuda.grid(1)\n","\n","\t# Compute pi by drawing random (x, y) points and finding what\n","\t# fraction lie inside a unit circle\n","\tinside = 0\n","\tfor i in range(iterations):\n","\t\tx = xoroshiro128p_uniform_float32(rng_states, tid)\n","\t\ty = xoroshiro128p_uniform_float32(rng_states, tid)\n","\t\tif x**2 + y**2 <= 1.0:\n","\t\t\tinside += 1\n","\n","\tout[tid] = 4.0 * inside / iterations"]},{"cell_type":"code","execution_count":null,"id":"959d9bd8","metadata":{"id":"959d9bd8"},"outputs":[],"source":["# params\n","n_iter = 100000     # Number of iterations per thread\n","threads_per_block = 1024\n","blocks = 1024\n","\n","# Create random number generator states\n","rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=1)\n","out = np.zeros(threads_per_block * blocks, dtype=np.float32)\n","d_output = cuda.to_device(out)\n","d_rng_states = cuda.to_device(rng_states)\n","\n","# Launch the kernel\n","compute_pi[blocks, threads_per_block](d_rng_states, n_iter, d_output)\n","\n","# Copy the result back to host\n","out = d_output.copy_to_host()\n","print('pi:', out.mean())\n","print('error:', np.abs(np.pi-out.mean()))"]},{"cell_type":"markdown","metadata":{"id":"l1p7zLJ6pBJ7"},"source":["‚Ü© TODO: Convolution 2D..."],"id":"l1p7zLJ6pBJ7"},{"cell_type":"code","execution_count":null,"metadata":{"id":"GH6V7uC3pC00"},"outputs":[],"source":["import math\n","from numba import cuda\n","\n","@cuda.jit\n","def Gauss_GPU(rng_states, iterations, out, a, b):\n","\n","\t# TODO\n"],"id":"GH6V7uC3pC00"},{"cell_type":"code","execution_count":null,"id":"2ff062d5","metadata":{"id":"2ff062d5"},"outputs":[],"source":["\n","n_iter = 100000     # Number of iterations per thread\n","threads_per_block = 1024\n","blocks = 1024\n","a = -1\n","b = 2\n","\n","# Create random number generator states\n","rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=1)\n","out = np.zeros(threads_per_block * blocks, dtype=np.float32)\n","d_output = cuda.to_device(out)\n","d_rng_states = cuda.to_device(rng_states)\n","\n","# Launch the kernel\n","Gauss_GPU[blocks, threads_per_block](d_rng_states, n_iter, d_output, a, b)\n","\n","# Copy the result back to host\n","out = d_output.copy_to_host()\n","print('prob:', out.mean())\n"]},{"cell_type":"markdown","id":"42df7879","metadata":{"id":"42df7879"},"source":["# üêç Mandelbrot"]},{"cell_type":"code","execution_count":null,"id":"9cbcb0cf","metadata":{"id":"9cbcb0cf"},"outputs":[],"source":["import math\n","\n","@cuda.jit\n","def mandelbrot_gpu(mat, maxiter=100, xmin=-2.6, xmax=1.85, ymin=-1.25, ymax=1.25):\n","\tx = cuda.blockIdx.x\n","\ty = cuda.threadIdx.x\n","\n","\t# Mapping pixel to C\n","\tcreal = xmin + x / mat.shape[0] * (xmax - xmin)\n","\tcim = ymin + y / mat.shape[1] * (ymax - ymin)\n","\n","\t# Initialisation of C and Z\n","\tc = complex(creal, cim)\n","\tz = complex(0, 0)\n","\n","\t# Mandelbrot iteration\n","\tfor n in range(maxiter):\n","\t\tz = z*z+c\n","\t\t# If unbounded: save iteration count and break\n","\t\tif z.real*z.real + z.imag*z.imag > 4.0:\n","\t\t\t# Smooth iteration count\n","\t\t\tmat[x,y] = n + 1 - math.log(math.log(abs(z*z+c)))/math.log(2)\n","\t\t\tbreak\n","\t\t# Otherwise: leave it to 0"]},{"cell_type":"code","execution_count":null,"id":"6b88bf03","metadata":{"id":"6b88bf03"},"outputs":[],"source":["# Parameters\n","xmin, xmax = -2.6, 1.85\n","ymin, ymax = -1.25, 1.25\n","xpixels = 512\n","ypixels = round(xpixels / (xmax-xmin) * (ymax-ymin))\n","\n","maxiter = 100\n","mat = np.zeros((xpixels, ypixels))\n","# Allocate device memory\n","d_mat = cuda.to_device(mat)\n","\n","# Running and plotting result\n","mandelbrot_gpu[xpixels, ypixels](d_mat, maxiter, xmin, xmax, ymin, ymax)\n","# Copy the result back to host\n","mat = d_mat.copy_to_host()\n","print(mat.shape)\n"]},{"cell_type":"code","execution_count":null,"id":"2ea66cba","metadata":{"id":"2ea66cba"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib as cm\n","\n","def draw_image(mat, cmap='inferno', powern=0.5, dpi=72):\n","  ## Value normalization\n","  # Apply power normalization, because number of iteration is\n","  # distributed according to a power law (fewer pixels have\n","  # higher iteration number)\n","  mat = np.power(mat, powern)\n","\n","  # Colormap: set the color the black for values under vmin (inner points of\n","  # the set), vmin will be set in the imshow function\n","  new_cmap = cm.colormaps[cmap]\n","  new_cmap.set_under('black')\n","\n","  ## Plotting image\n","\n","  # Figure size\n","  plt.figure(figsize=(mat.shape[0]/dpi, mat.shape[1]/dpi))\n","\n","  # Plotting mat with cmap\n","  # vmin=1 because smooth iteration count is always > 1\n","  # We need to transpose mat because images use row-major\n","  # ordering (C convention)\n","  # origin='lower' because mat[0,0] is the lower left pixel\n","  plt.imshow(mat.T, cmap=new_cmap, vmin=1, origin = 'lower')\n","\n","  # Remove axis and margins\n","  plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n","  plt.axis('off')\n","\n","\n","draw_image(mat)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"},"colab":{"provenance":[{"file_id":"14F-X9WzRzdGLr7h5bYYXXmc1DjzHzDtj","timestamp":1747257236369}],"collapsed_sections":["-_i3qX0HhLrV","32aab92c","654daecb","cb659914","655752a3","a82ccc30","67a5faae","42df7879"],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}