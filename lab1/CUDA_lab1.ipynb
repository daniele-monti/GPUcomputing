<<<<<<< Updated upstream
{"cells":[{"cell_type":"markdown","metadata":{"id":"ivxGuz4MVBBQ"},"source":["---\n","# **LAB 1 - Intro CUDA**\n","---"]},{"cell_type":"markdown","metadata":{"id":"9YGa6hXkx77o"},"source":["# ▶️ Google Colaboratory (colab)"]},{"cell_type":"markdown","metadata":{"id":"F-lZoo4TstJn"},"source":["[Colaboratory](https://research.google.com/colaboratory/faq.html) (or Colab) is a **free research tool** from *Google* for machine learning education and research built on top of [Jupyter Notebook](https://jupyter.org/). It requires no setup and runs entirely in the **cloud**. In Google Colab you can write, execute, save and share your Jupiter Notebooks. You access powerful computing resources like **TPUs** and **GPUs** all for free through your browser. All major Python libraries like **Tensorflow**, **Scikit-learn**, **PyTorch**, **Pandas**, etc. are pre-installed. Google Colab requires no configuration, you only need a **Google Account** and then you are good to go. Your notebooks are stored in your **Google Drive**, or can be loaded from **GitHub**. Colab notebooks can be shared just as you would with Google Docs or Sheets. Simply click the Share button at the top right of any Colab notebook, or follow these Google Drive file sharing instructions.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zfPMRBrqzjjb"},"source":["##Upload/download files\n","\n","\n","Once you open a **Google Colab notebook**, it creates a **virtual machine** instance on a Google Cloud Platform. To **upload** files from your local machine to Colab virtual storage, use `upload` option from the left sidebar. To **download** files from Colab's virtual storage to your local machine, right-click on a file and then select `Download`. You can also mount your google drive: once you click on **MOUNT DRIVE** in the left sidebar, it will insert a code cell into your notebook that you'll need to run to mount your google drive (it will ask for your authorization). Another way to download files (without mounting a google drive) is to use a `!gdown` or `!wget` commands (more details in the [Shell commands](#scrollTo=JrF12-bqPKPm) section)<br><br>\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1CRjolVrVbEboNPLVVw-c_AtsBBcSou1Z\" width=800 px><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZvWtrdMfxQD8"},"source":["## Notebook rules\n","\n","Some basic notebook rules:\n","\n","\n","1.   Click inside a cell with code and press SHIFT+ENTER (or click \"PLAY\" button) to execute it.\n","2.   Re-executing a cell will reset it (any input will be lost).\n","3.   Execute cells TOP TO BOTTOM.\n","5. Notebooks are saved to your Google Drive\n","6. Mount your Google Drive to have a direct access from a notebook to the files stored in the drive (this includes Team Drives).\n","7. If using Colab's virtual storage only, all the uploaded/stored files will get deleted when a runtime is recycled."]},{"cell_type":"markdown","metadata":{"id":"ulev4sV3wc-T"},"source":["## Shell commands"]},{"cell_type":"markdown","metadata":{"id":"fS67zRIavQtS"},"source":["The command `uname` displays the information about the system.\n","\n","* **-a option:** It prints all the system information in the following order: Kernel name, network node hostname,\n","kernel release date, kernel version, machine hardware name, hardware platform, operating system\n","."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PT7Umr53u2Qz"},"outputs":[],"source":["!uname -a && cat /etc/*release"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1h8YWW1RzEN"},"outputs":[],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_fkW3x5hu85"},"outputs":[],"source":["!ls -la"]},{"cell_type":"markdown","metadata":{"id":"F9PmBZql0ow4"},"source":["# ▶️ CUDA zone"]},{"cell_type":"markdown","metadata":{"id":"Ur7-3SF3h4vy"},"source":["## How to use accelerated hardware\n","\n","To change hardware runtime you just have to navigate from `Runtime -> change runtime` type and select your preferred accelerated hardware type **GPU** or **TPU**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nTRXba1Msgq2"},"source":["**NVIDIA System Management Interface (nvidia-smi)**\n","\n","The NVIDIA System Management Interface (**`nvidia-smi`**) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the **management** and **monitoring** of NVIDIA GPU devices.\n","\n","This utility allows administrators to query GPU device state and with the appropriate privileges, permits administrators to modify GPU device state.  It is targeted at the TeslaTM, GRIDTM, QuadroTM and Titan X product, though limited support is also available on other NVIDIA GPUs.\n","\n","For more details, please refer to the **`nvidia-smi`** documentation ([doc](http://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf))\n","\n","For information on **Tesla T4** see:"]},{"cell_type":"code","source":["!nvcc --version"],"metadata":{"id":"bUECwNtuDm2d"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlXMCnBVBkeE"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"gcg1GyK5srek"},"source":["## GPU computing notebooks download (from github)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyHOxci3s3H8"},"outputs":[],"source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"3RDr9PREJBnA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"227eLdP5csN1"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","**Cell Magic**\n","\n","Defines the `%cuda` cell magic command to run a simple hello world program.\n","\n","**Groups**\n","\n","If you want to split your code into multiple source files, either for code reuse or just to have an easier to read project, you want to use groups. A group of source files will be compiled together. Because of this, you can include headers from the same group and use the code defined in other `.cu` files. There is also a special group named `shared` whose files will be compiled together with all other groups.\n","\n","*Usage*:\n","- In order to have multiple source files in the special group named `shared` we need to use the `cuda_group_save` magic:\n","  - `%%cuda_group_save --group shared --name \"file.h\"`\n","- In order to have multiple source files we need to use the `cuda_group_save` magic:\n","  - `%%cuda_group_save --name \"file.cu\" --group \"project\"`\n","- To compile all the source files in the group and execute the main function we need the following command:\n","  - `%%cuda_group_run --group \"project\"`\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4TzxMBFds8aT"},"outputs":[],"source":["%cd GPUcomputing/utils/nvcc4jupyter-master/\n","!!python3 -m build\n","%load_ext nvcc4jupyter\n","%cd /content/"]},{"cell_type":"markdown","metadata":{"id":"r9QDvdB8xAuX"},"source":["To use also a plugin for cpp sintax highlighting..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FvkjBRIk070c","collapsed":true},"outputs":[],"source":["!wget -O cpp_plugin.py https://gist.github.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py\n","%load_ext cpp_plugin"]},{"cell_type":"markdown","metadata":{"id":"mB94Ce6kViOj"},"source":["# ✅ Hello World!"]},{"cell_type":"markdown","metadata":{"id":"sIlUaQYgdooS"},"source":["My first CUDA program: HelloFromGPU!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RlbVvBaXCHBs"},"outputs":[],"source":["%%cuda_group_save --name \"hello_world.cu\" --group \"misc\"\n","#include <stdio.h>\n","\n","// kernel: helloFromGPU\n","__global__ void helloFromGPU (void) {\n","  int tID = threadIdx.x;\n","  printf(\"Hello World from GPU (I'am thread %d)!\\n\", tID);\n","}\n","\n","// MAIN function\n","int main(void) {\n","  // hello from GPU\n","  printf(\"Hello World from CPU!\\n\");\n","  cudaSetDevice(0);\n","  helloFromGPU <<<1, 10>>>();\n","  cudaDeviceSynchronize();\n","  return 0;\n","}\n"]},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/misc/hello_world.cu -o helloworld\n","!./helloworld"],"metadata":{"id":"lkTbuWOt1kMA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00kgrJDtaoEU"},"outputs":[],"source":["%%cuda\n","#include <stdio.h>\n","#include <iostream>\n","\n","using namespace std;\n","\n","//#  kernel: helloFromGPU\n","# TODO...\n","\n","// Main function\n","int main(void) {\n","  //# hello from GPU\n","  cout << \"Hello World from CPU!\" << endl;\n","\n","  # TODO...\n","\n","  return 0;\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"1VJXO5U8JSGz"},"source":["# ✅ cumsum in a vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXvrYYqCJaWk"},"outputs":[],"source":["%%cuda_group_save --name \"cumsum.cu\" --group \"misc\"\n","\n","#include <stdio.h>\n","#include <time.h>\n","#include <stdlib.h>\n","\n","\n","// kernel cumsum\n","__global__ void cumsum(const float *A, float *B, int num_thread) {\n","\n","    int idx = threadIdx.x;\n","    float s = 0.0f;\n","\n","    if (idx < num_thread) {\n","      for (int i = 0; i <= idx; i++)\n","        s += A[i];\n","      B[idx] = s;\n","    }\n","}\n","\n","// Main function\n","int main(){\n","  const int num_thread = 1024;     //# <= 1024\n","  srand(time(NULL)); // seed for rand()\n","\n","  float *h_A, *h_B, *d_A, *d_B;\n","  size_t bytes = num_thread * sizeof(float);\n","\n","  // allocate space for vectors in host memory\n","  h_A = (float *) malloc(bytes);\n","  h_B = (float *) malloc(bytes);\n","\n","  // put 1 in the array\n","  for (int i = 0; i < num_thread; i++) {\n","    h_A[i] = 1.0;\n","  }\n","\n","  // allocate space for vectors in device memory\n","  cudaMalloc(&d_A, bytes);\n","  cudaMalloc(&d_B, bytes);\n","\n","  // copy vectors A and B from host to device:\n","  cudaMemcpy(d_A, h_A, bytes, cudaMemcpyHostToDevice);\n","\n","  // launch the vector adding kernel\n","  cumsum<<<1, num_thread>>>(d_A, d_B, num_thread);\n","\n","  // wait for the kernel to finish execution\n","  cudaDeviceSynchronize();\n","\n","  // copy from device memory\n","  cudaMemcpy(h_B, d_B, bytes, cudaMemcpyDeviceToHost);\n","\n","  // print results\n","  for (int i=0; i<10; i++) {\n","    int j = rand() % num_thread;\n","    printf(\"B[%d] = %f\\n\", j, h_B[j]);\n","  }\n","\n","  return 0;\n","}"]},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/misc/cumsum.cu -o cumsum\n","!./cumsum\n"],"metadata":{"id":"paAOCvf61LxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ku--dgMncvGP"},"source":["### ↘️ *`TODO...`*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQqlbHQgcpAR"},"outputs":[],"source":["%%cuda_group_save --name \"cumsum.cu\" --group \"misc\"\n","\n","#include <stdio.h>\n","#include <time.h>\n","#include <stdlib.h>\n","\n","\n","// kernel cumsum\n","\n","\n","// Main function\n","int main(){\n","\n","  // allocate space for vectors in host memory\n","\n","  // put 1 in the array\n","\n","  // allocate space for vectors in device memory\n","\n","  // copy vectors A and B from host to device:\n","\n","  // launch the vector adding kernel\n","\n","  // wait for the kernel to finish execution\n","\n","  // copy from device memory\n","\n","  // print some results\n","\n","  return 0;\n","}"]},{"cell_type":"markdown","metadata":{"id":"4bll8pe7Fj3y"},"source":["#  ✅ MQDB: Matrici quadrate diagonali a blocchi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMp_CpISiVvH"},"outputs":[],"source":["%mkdir -p MQDB\n","%ls -la"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mbG20QCi7G6T"},"outputs":[],"source":["%%cpp -n MQDB/mqdb.h -s xcode\n","\n","#ifndef MQDB_H\n","#define MQDB_H\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <string.h>\n","#include <math.h>\n","#include <sys/time.h>\n","#include <time.h>\n","\n","#define randu() ((float)rand() / (float) RAND_MAX)\n","#define abs(x) ((x)<0 ? (-x) : (x))\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","typedef struct MQDB {\n","\tchar desc[100];   // description\n","\tint nBlocks;      // num. of blocks\n","\tint *blkSize;     // block dimensions\n","\tfloat *elem;       // elements in row-major order\n","\tulong nElems;     // actual number of elements\n","} mqdb;\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","// # function prototypes #\n","int genRandDims(mqdb*, uint, uint);\n","void fillBlocks(mqdb*, uint, uint, char, float);\n","mqdb mqdbConst(uint, uint, uint, float);\n","void mqdbProd(mqdb, mqdb, mqdb);\n","void matProd(mqdb, mqdb, mqdb);\n","void checkResult(mqdb, mqdb);\n","void mqdbDisplay(mqdb);\n","\n","inline double seconds() {\n","    struct timeval tp;\n","    struct timezone tzp;\n","    int i = gettimeofday(&tp, &tzp);\n","    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n","}\n","\n","#endif"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiDq208h8qmn"},"outputs":[],"source":["#@title  File: MQDB/mqdb.cpp\n","%%cpp -n MQDB/mqdb.cpp -s xcode\n","\n","#include \"mqdb.h\"\n","\n","/**\n"," * random generate block dimensions\n"," */\n","int genRandDims(mqdb *M, uint n, uint k) {\n","\n","\tif (n == 0 || k == 0 || k > n) {\n","\t\tprintf(\"error: n,k must be positive and n > k!\\n\");\n","\t\treturn(-1);\n","\t}\n","\t// random generation of block sizes\n","\tM->blkSize = (int *) malloc(k * sizeof(int));\n","\tint sum = 0;\n","\tint r;\n","\tfloat mu = 2.0f * (float) n / (float) k;\n","\tfor (int i = 0; i < k - 1; i++) {\n","\t\t// expected value E[block_size] = n/k\n","\t\twhile ((r = round(mu * randu())) > n - sum - k + i + 1);\n","\t\tif (!r)\n","\t\t\tr += 1;\n","\t\tM->blkSize[i] = r;\n","\t\tsum += r;\n","\t}\n","\tM->blkSize[k - 1] = n - sum;\n","\treturn(0);\n","}\n","\n","/**\n"," * # fill blocks either random or constant #\n"," */\n","void fillBlocks(mqdb *M, uint n, uint k, char T, float c) {\n","\t// mat size n*n\n","\tM->elem = (float *) calloc(n * n, sizeof(float));\n","\tM->nElems = 0;\n","\tint offset = 0;\n","\t// # loop on blocks #\n","\tfor (int i = 0; i < k; i++) {\n","\t\tfor (int j = 0; j < M->blkSize[i]; j++)\n","\t\t\tfor (int k = 0; k < M->blkSize[i]; k++)\n","\t\t\t\tif (T == 'C')  \t    // const fill mat entries\n","\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = c;\n","\t\t\t\telse if (T == 'R') \t// random fill mat entries\n","\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = randu();\n","\t\toffset += M->blkSize[i];\n","\t\tM->nElems += M->blkSize[i]*M->blkSize[i];\n","\t}\n","\t// set description\n","\tsprintf(M->desc, \"Random mqdb:  mat. size = %d, num. blocks = %d, blk sizes: \",n,k);\n","}\n","\n","/**\n"," * rand_gen_mqdb: mqdb  type returned\n"," *                n     square matrix size\n"," *                k     number of blocks\n"," *                seed  seed for random generator\n"," */\n","mqdb genRandMat(unsigned n, unsigned k, unsigned seed) {\n","\tmqdb M;\n","\tsrand(seed);\n","\tgenRandDims(&M, n, k);\n","\tM.nBlocks = k;\n","\n","\tsrand(time(NULL));\n","\t// random fill mat entries\n","\tfillBlocks(&M, n, k, 'R', 0.0);\n","\n","\treturn M;\n","}\n","\n","/**\n"," * const_mqdb: mqdb     is the type returned\n"," *                n     is the square matrix size\n"," *                k     is the number of blocks\n"," *                seed  is the seed for random generator\n"," *                c   \tis the constant value assigned\n"," */\n","mqdb mqdbConst(uint n, uint k, uint seed, float c) {\n","\tmqdb M;\n","\tsrand(seed);\n","\tgenRandDims(&M, n, k);\n","\tM.nBlocks = k;\n","\n","\t// fill mat entries with a constant\n","\tfillBlocks(&M, n, k, 'C', c);\n","\n","\treturn M;\n","}\n","\n","/*\n"," * standard (naive) matrix product on host\n"," */\n","void matProd(mqdb A, mqdb B, mqdb C) {\n","\tint n = 0;\n","\tfor (uint i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];\n","\n","\tfor (uint r = 0; r < n; r++)\n","\t\tfor (uint c = 0; c < n; c++) {\n","\t\t\tdouble sum = 0;\n","\t\t\tfor (uint l = 0; l < n; l++){\n","\t\t\t\tdouble a = A.elem[r * n + l];\n","\t\t\t\tdouble b = B.elem[l * n + c];\n","\t\t\t\tsum += a*b;\n","\t\t\t}\n","\t\t\tC.elem[r * n + c] = (float)sum;\n","\t\t}\n","}\n","\n","/*\n"," * elementwise comparison between two mqdb\n"," */\n","void checkResult(mqdb A, mqdb B) {\n","\tdouble epsilon = 1.0E-8;\n","\tbool match = 1;\n","\tint n = 0;\n","\tfor (int i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];\n","\tfor (int i = 0; i < n * n; i++) {\n","\t\tif (fabs(A.elem[i] - B.elem[i]) > epsilon) {\n","\t\t\tmatch = 0;\n","\t\t\tprintf(\"   * Arrays do not match!\\n\");\n","\t\t\tprintf(\"     gpu: %2.2f,  host: %2.2f at current %d\\n\", A.elem[i],\n","\t\t\t\t\tB.elem[i], i);\n","\t\t\tbreak;\n","\t\t}\n","\t}\n","\tif (match)\n","\t\tprintf(\"   Arrays match\\n\\n\");\n","}\n","/*\n"," * print mqdb\n"," */\n","void mqdbDisplay(mqdb M) {\n","\tint n = 0;\n","\tprintf(\"%s\", M.desc);\n","\tfor (int j = 0; j < M.nBlocks; j++) {\n","\t\tprintf(\"%d  \", M.blkSize[j]);\n","\t\tn += M.blkSize[j];\n","\t}\n","\tprintf(\"\\n\");\n","\tfor (int j = 0; j < n * n; j++) {\n","\t\tif (M.elem[j] == 0)\n","\t\t\tprintf(\"------\");\n","\t\telse\n","\t\t\tprintf(\"%5.2f \", M.elem[j]);\n","\t\tif ((j + 1) % n == 0)\n","\t\t\tprintf(\"\\n\");\n","\t}\n","\tprintf(\"\\n\");\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"Ic7TGi3QeZny"},"source":["### ↘️ *`TODO...`*"]},{"cell_type":"markdown","metadata":{"id":"_QMShprZETnd"},"source":["Sviluppare una funzione `C` per effettuare il prodotto ottimizzato (ristretto ai soli blocchi sulla diagonale) tra due matrici $C=A*B$ ti tipo MQDB.\n","\n","**PASSI**\n","\n","1. fissare i parametri principali: `n` dimesione della matrice, `k` numero di blocchi sulla diagonale\n","2. generare matrici a caso `genRandMat(uint n, uint k, uint seed)` o con valore costante `mqdbConst(uint n, uint k, uint seed, float c)`.\n","Nota: Le dimensioni dei blocchi $k_i$, tale che $n = \\sum_{i=1}^k k_i$, viene generata a caso\n","3. Le matrici devono avere uguale dimensione (stesso lato $n$ e ugual dimensione $k_i$ dei $k$ blocchi sulla diagonale - usare stesso seed)\n","\n","<img src=\"https://github.com/giulianogrossi/imgs/blob/main/GPU/MQDB.png?raw=true\" align=\"center\" width=600px >"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3dBgacxi9qu"},"outputs":[],"source":["%%cpp -n MQDB/prod_mqdb.cpp -s xcode\n","\n","#include \"mqdb.h\"\n","\n","/*\n"," * product between mqdb matrices restricted to blocks\n"," */\n","void mqdbProd(mqdb A, mqdb B, mqdb C) {\n","\tuint n = 0;\n","\tfor (uint i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];                    // mat dim\n","\tint k = A.nBlocks;                      // num blks\n","\tint dl = 0;                             // blk left bound\n","\tint dr = 0;                             // blk left bound\n","\tfor (uint i = 0; i < k; i++) {          // loop on blks\n","\t\tdr += A.blkSize[i];                   // blk right bound\n","\t\tfor (uint r = dl; r < dr; r++) {      // scan block rows\n","\t\t\tfor (uint c = dl; c < dr; c++) {    // scan block cols\n","\t\t\t\tfloat s = 0;\n","\t\t\t\tfor (uint l = dl; l < dr; l++)\n","\t\t\t\t\ts += A.elem[r*n + l] * B.elem[c + l * n];\n","\t\t\t\tC.elem[r*n + c] = s;\n","\t\t\t}\n","\t\t}\n","\t\tdl = dr;\n","\t}\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"IO7kSHrFi9qu"},"source":["Template..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtdrHhgOcoJI"},"outputs":[],"source":["%%cpp -n MQDB/prod_mqdb.cpp -s xcode\n","\n","#include \"mqdb.h\"\n","\n","# TODO..."]},{"cell_type":"markdown","metadata":{"id":"1CSpZ6wplPmy"},"source":["Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r19AgzDRBJh3"},"outputs":[],"source":["%%cpp -n  MQDB/main.cpp\n","#include <sys/time.h>\n","#include \"mqdb.h\"\n","\n","/*\n"," * main function\n"," */\n","int main(void) {\n","\tuint n = 2*1024;      // matrix size\n","  uint k = 10;          // num of blocks\n","\tmqdb A, B, C, C1;     // mqdb host matrices\n","\n","\t// # fill in #\n","\tA = mqdbConst(n, k, 10, 1);\n","\tB = mqdbConst(n, k, 10, 1);\n","\tC = mqdbConst(n, k, 10, 1);\n","\tC1 = mqdbConst(n, k, 10, 1);\n","\n","\tulong nBytes = n * n * sizeof(float);\n","\tulong kBytes = k * sizeof(uint);\n","\tprintf(\"Memory size required = %.1f (MB)\\n\",(float)nBytes/(1024.0*1024.0));\n","\n","\tprintf(\"CPU mat product...\\n\");\n","\tdouble start = seconds();\n","  matProd(A, B, C);\n","\tdouble CPUTime = seconds() - start;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n","\n","  printf(\"CPU MQDB product...\\n\");\n","\tstart = seconds();\n","  mqdbProd(A, B, C1);\n","\tCPUTime = seconds() - start;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n","\n","\t// check result\n","\tcheckResult(C, C1);\n","\n","\treturn 0;\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kWihzIB84j1"},"outputs":[],"source":["%%shell\n","# Compilazione ed esecuzione\n","\n","g++ MQDB/prod_mqdb.cpp MQDB/main.cpp MQDB/mqdb.cpp -o main\n","./main"]},{"cell_type":"markdown","metadata":{"id":"JrC7365ckKJ6"},"source":["## Report\n","\n","Riportare i tempi di esecuzione per\n","\n","$k = 10$\n","* n = 1024, time =\n","* n = 2048, time =\n","* n = 4096, time =\n","\n","$k = 20$\n","* n = 1024, time =\n","* n = 2048, time =\n","* n = 4096, time ="]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["9YGa6hXkx77o","F9PmBZql0ow4","227eLdP5csN1","mB94Ce6kViOj","4bll8pe7Fj3y"],"private_outputs":true,"provenance":[{"file_id":"1WU0UNEexcE6n3hufdRUgHmlSvXnClfr4","timestamp":1677494778770},{"file_id":"1IFQanBdBBUzqheWXiloaVlYrS_p2zjrL","timestamp":1677229457617}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
=======
{"cells":[{"cell_type":"markdown","metadata":{"id":"ivxGuz4MVBBQ"},"source":["---\n","# **LAB 1 - Intro CUDA**\n","---"]},{"cell_type":"markdown","metadata":{"id":"9YGa6hXkx77o"},"source":["# ▶️ Google Colaboratory (colab)"]},{"cell_type":"markdown","metadata":{"id":"F-lZoo4TstJn"},"source":["[Colaboratory](https://research.google.com/colaboratory/faq.html) (or Colab) is a **free research tool** from *Google* for machine learning education and research built on top of [Jupyter Notebook](https://jupyter.org/). It requires no setup and runs entirely in the **cloud**. In Google Colab you can write, execute, save and share your Jupiter Notebooks. You access powerful computing resources like **TPUs** and **GPUs** all for free through your browser. All major Python libraries like **Tensorflow**, **Scikit-learn**, **PyTorch**, **Pandas**, etc. are pre-installed. Google Colab requires no configuration, you only need a **Google Account** and then you are good to go. Your notebooks are stored in your **Google Drive**, or can be loaded from **GitHub**. Colab notebooks can be shared just as you would with Google Docs or Sheets. Simply click the Share button at the top right of any Colab notebook, or follow these Google Drive file sharing instructions.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zfPMRBrqzjjb"},"source":["##Upload/download files\n","\n","\n","Once you open a **Google Colab notebook**, it creates a **virtual machine** instance on a Google Cloud Platform. To **upload** files from your local machine to Colab virtual storage, use `upload` option from the left sidebar. To **download** files from Colab's virtual storage to your local machine, right-click on a file and then select `Download`. You can also mount your google drive: once you click on **MOUNT DRIVE** in the left sidebar, it will insert a code cell into your notebook that you'll need to run to mount your google drive (it will ask for your authorization). Another way to download files (without mounting a google drive) is to use a `!gdown` or `!wget` commands (more details in the [Shell commands](#scrollTo=JrF12-bqPKPm) section)<br><br>\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1CRjolVrVbEboNPLVVw-c_AtsBBcSou1Z\" width=800 px><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZvWtrdMfxQD8"},"source":["## Notebook rules\n","\n","Some basic notebook rules:\n","\n","\n","1.   Click inside a cell with code and press SHIFT+ENTER (or click \"PLAY\" button) to execute it.\n","2.   Re-executing a cell will reset it (any input will be lost).\n","3.   Execute cells TOP TO BOTTOM.\n","5. Notebooks are saved to your Google Drive\n","6. Mount your Google Drive to have a direct access from a notebook to the files stored in the drive (this includes Team Drives).\n","7. If using Colab's virtual storage only, all the uploaded/stored files will get deleted when a runtime is recycled."]},{"cell_type":"markdown","metadata":{"id":"ulev4sV3wc-T"},"source":["## Shell commands"]},{"cell_type":"markdown","metadata":{"id":"fS67zRIavQtS"},"source":["The command `uname` displays the information about the system.\n","\n","* **-a option:** It prints all the system information in the following order: Kernel name, network node hostname,\n","kernel release date, kernel version, machine hardware name, hardware platform, operating system\n","."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PT7Umr53u2Qz"},"outputs":[],"source":["!uname -a && cat /etc/*release"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1h8YWW1RzEN"},"outputs":[],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_fkW3x5hu85"},"outputs":[],"source":["!ls -la"]},{"cell_type":"markdown","metadata":{"id":"F9PmBZql0ow4"},"source":["# ▶️ CUDA zone"]},{"cell_type":"markdown","metadata":{"id":"Ur7-3SF3h4vy"},"source":["## How to use accelerated hardware\n","\n","To change hardware runtime you just have to navigate from `Runtime -> change runtime` type and select your preferred accelerated hardware type **GPU** or **TPU**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nTRXba1Msgq2"},"source":["**NVIDIA System Management Interface (nvidia-smi)**\n","\n","The NVIDIA System Management Interface (**`nvidia-smi`**) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the **management** and **monitoring** of NVIDIA GPU devices.\n","\n","This utility allows administrators to query GPU device state and with the appropriate privileges, permits administrators to modify GPU device state.  It is targeted at the TeslaTM, GRIDTM, QuadroTM and Titan X product, though limited support is also available on other NVIDIA GPUs.\n","\n","For more details, please refer to the **`nvidia-smi`** documentation ([doc](http://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf))\n","\n","For information on **Tesla T4** see:"]},{"cell_type":"code","source":["!nvcc --version"],"metadata":{"id":"bUECwNtuDm2d"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlXMCnBVBkeE"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"gcg1GyK5srek"},"source":["## GPU computing notebooks download (from github)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyHOxci3s3H8"},"outputs":[],"source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"3RDr9PREJBnA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"227eLdP5csN1"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","**Cell Magic**\n","\n","Defines the `%cuda` cell magic command to run a simple hello world program.\n","\n","**Groups**\n","\n","If you want to split your code into multiple source files, either for code reuse or just to have an easier to read project, you want to use groups. A group of source files will be compiled together. Because of this, you can include headers from the same group and use the code defined in other `.cu` files. There is also a special group named `shared` whose files will be compiled together with all other groups.\n","\n","*Usage*:\n","- In order to have multiple source files in the special group named `shared` we need to use the `cuda_group_save` magic:\n","  - `%%cuda_group_save --group shared --name \"file.h\"`\n","- In order to have multiple source files we need to use the `cuda_group_save` magic:\n","  - `%%cuda_group_save --name \"file.cu\" --group \"project\"`\n","- To compile all the source files in the group and execute the main function we need the following command:\n","  - `%%cuda_group_run --group \"project\"`\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4TzxMBFds8aT"},"outputs":[],"source":["%cd GPUcomputing/utils/nvcc4jupyter-master/\n","!!python3 -m build\n","%load_ext nvcc4jupyter\n","%cd /content/"]},{"cell_type":"markdown","metadata":{"id":"r9QDvdB8xAuX"},"source":["To use also a plugin for cpp sintax highlighting..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FvkjBRIk070c","collapsed":true},"outputs":[],"source":["!wget -O cpp_plugin.py https://gist.github.com/akshaykhadse/7acc91dd41f52944c6150754e5530c4b/raw/cpp_plugin.py\n","%load_ext cpp_plugin"]},{"cell_type":"markdown","metadata":{"id":"mB94Ce6kViOj"},"source":["# ✅ Hello World!"]},{"cell_type":"markdown","metadata":{"id":"sIlUaQYgdooS"},"source":["My first CUDA program: HelloFromGPU!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RlbVvBaXCHBs"},"outputs":[],"source":["%%cuda_group_save --name \"hello_world.cu\" --group \"misc\"\n","#include <stdio.h>\n","\n","// kernel: helloFromGPU\n","__global__ void helloFromGPU (void) {\n","  int tID = threadIdx.x;\n","  printf(\"Hello World from GPU (I'am thread %d)!\\n\", tID);\n","}\n","\n","// MAIN function\n","int main(void) {\n","  // hello from GPU\n","  printf(\"Hello World from CPU!\\n\");\n","  cudaSetDevice(0);\n","  helloFromGPU <<<1, 10>>>();\n","  cudaDeviceSynchronize();\n","  return 0;\n","}\n"]},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/misc/hello_world.cu -o helloworld\n","!./helloworld"],"metadata":{"id":"lkTbuWOt1kMA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00kgrJDtaoEU"},"outputs":[],"source":["%%cuda\n","#include <stdio.h>\n","#include <iostream>\n","\n","using namespace std;\n","\n","//#  kernel: helloFromGPU\n","# TODO...\n","\n","// Main function\n","int main(void) {\n","  //# hello from GPU\n","  cout << \"Hello World from CPU!\" << endl;\n","\n","  # TODO...\n","\n","  return 0;\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"1VJXO5U8JSGz"},"source":["# ✅ cumsum in a vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXvrYYqCJaWk"},"outputs":[],"source":["%%cuda_group_save --name \"cumsum.cu\" --group \"misc\"\n","\n","#include <stdio.h>\n","#include <time.h>\n","#include <stdlib.h>\n","\n","\n","// kernel cumsum\n","__global__ void cumsum(const float *A, float *B, int num_thread) {\n","\n","    int idx = threadIdx.x;\n","    float s = 0.0f;\n","\n","    if (idx < num_thread) {\n","      for (int i = 0; i <= idx; i++)\n","        s += A[i];\n","      B[idx] = s;\n","    }\n","}\n","\n","// Main function\n","int main(){\n","  const int num_thread = 1024;     //# <= 1024\n","  srand(time(NULL)); // seed for rand()\n","\n","  float *h_A, *h_B, *d_A, *d_B;\n","  size_t bytes = num_thread * sizeof(float);\n","\n","  // allocate space for vectors in host memory\n","  h_A = (float *) malloc(bytes);\n","  h_B = (float *) malloc(bytes);\n","\n","  // put 1 in the array\n","  for (int i = 0; i < num_thread; i++) {\n","    h_A[i] = 1.0;\n","  }\n","\n","  // allocate space for vectors in device memory\n","  cudaMalloc(&d_A, bytes);\n","  cudaMalloc(&d_B, bytes);\n","\n","  // copy vectors A and B from host to device:\n","  cudaMemcpy(d_A, h_A, bytes, cudaMemcpyHostToDevice);\n","\n","  // launch the vector adding kernel\n","  cumsum<<<1, num_thread>>>(d_A, d_B, num_thread);\n","\n","  // wait for the kernel to finish execution\n","  cudaDeviceSynchronize();\n","\n","  // copy from device memory\n","  cudaMemcpy(h_B, d_B, bytes, cudaMemcpyDeviceToHost);\n","\n","  // print results\n","  for (int i=0; i<10; i++) {\n","    int j = rand() % num_thread;\n","    printf(\"B[%d] = %f\\n\", j, h_B[j]);\n","  }\n","\n","  return 0;\n","}"]},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/misc/cumsum.cu -o cumsum\n","!./cumsum\n"],"metadata":{"id":"paAOCvf61LxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ku--dgMncvGP"},"source":["### ↘️ *`TODO...`*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQqlbHQgcpAR"},"outputs":[],"source":["%%cuda_group_save --name \"cumsum.cu\" --group \"misc\"\n","\n","#include <stdio.h>\n","#include <time.h>\n","#include <stdlib.h>\n","\n","\n","// kernel cumsum\n","\n","\n","// Main function\n","int main(){\n","\n","  // allocate space for vectors in host memory\n","\n","  // put 1 in the array\n","\n","  // allocate space for vectors in device memory\n","\n","  // copy vectors A and B from host to device:\n","\n","  // launch the vector adding kernel\n","\n","  // wait for the kernel to finish execution\n","\n","  // copy from device memory\n","\n","  // print some results\n","\n","  return 0;\n","}"]},{"cell_type":"markdown","metadata":{"id":"4bll8pe7Fj3y"},"source":["#  ✅ MQDB: Matrici quadrate diagonali a blocchi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMp_CpISiVvH"},"outputs":[],"source":["%mkdir -p MQDB\n","%ls -la"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mbG20QCi7G6T"},"outputs":[],"source":["%%cpp -n MQDB/mqdb.h -s xcode\n","\n","#ifndef MQDB_H\n","#define MQDB_H\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <string.h>\n","#include <math.h>\n","#include <sys/time.h>\n","#include <time.h>\n","\n","#define randu() ((float)rand() / (float) RAND_MAX)\n","#define abs(x) ((x)<0 ? (-x) : (x))\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","typedef struct MQDB {\n","\tchar desc[100];   // description\n","\tint nBlocks;      // num. of blocks\n","\tint *blkSize;     // block dimensions\n","\tfloat *elem;       // elements in row-major order\n","\tulong nElems;     // actual number of elements\n","} mqdb;\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","// # function prototypes #\n","int genRandDims(mqdb*, uint, uint);\n","void fillBlocks(mqdb*, uint, uint, char, float);\n","mqdb mqdbConst(uint, uint, uint, float);\n","void mqdbProd(mqdb, mqdb, mqdb);\n","void matProd(mqdb, mqdb, mqdb);\n","void checkResult(mqdb, mqdb);\n","void mqdbDisplay(mqdb);\n","\n","inline double seconds() {\n","    struct timeval tp;\n","    struct timezone tzp;\n","    int i = gettimeofday(&tp, &tzp);\n","    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n","}\n","\n","#endif"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiDq208h8qmn"},"outputs":[],"source":["#@title  File: MQDB/mqdb.cpp\n","%%cpp -n MQDB/mqdb.cpp -s xcode\n","\n","#include \"mqdb.h\"\n","\n","/**\n"," * random generate block dimensions\n"," */\n","int genRandDims(mqdb *M, uint n, uint k) {\n","\n","\tif (n == 0 || k == 0 || k > n) {\n","\t\tprintf(\"error: n,k must be positive and n > k!\\n\");\n","\t\treturn(-1);\n","\t}\n","\t// random generation of block sizes\n","\tM->blkSize = (int *) malloc(k * sizeof(int));\n","\tint sum = 0;\n","\tint r;\n","\tfloat mu = 2.0f * (float) n / (float) k;\n","\tfor (int i = 0; i < k - 1; i++) {\n","\t\t// expected value E[block_size] = n/k\n","\t\twhile ((r = round(mu * randu())) > n - sum - k + i + 1);\n","\t\tif (!r)\n","\t\t\tr += 1;\n","\t\tM->blkSize[i] = r;\n","\t\tsum += r;\n","\t}\n","\tM->blkSize[k - 1] = n - sum;\n","\treturn(0);\n","}\n","\n","/**\n"," * # fill blocks either random or constant #\n"," */\n","void fillBlocks(mqdb *M, uint n, uint k, char T, float c) {\n","\t// mat size n*n\n","\tM->elem = (float *) calloc(n * n, sizeof(float));\n","\tM->nElems = 0;\n","\tint offset = 0;\n","\t// # loop on blocks #\n","\tfor (int i = 0; i < k; i++) {\n","\t\tfor (int j = 0; j < M->blkSize[i]; j++)\n","\t\t\tfor (int k = 0; k < M->blkSize[i]; k++)\n","\t\t\t\tif (T == 'C')  \t    // const fill mat entries\n","\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = c;\n","\t\t\t\telse if (T == 'R') \t// random fill mat entries\n","\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = randu();\n","\t\toffset += M->blkSize[i];\n","\t\tM->nElems += M->blkSize[i]*M->blkSize[i];\n","\t}\n","\t// set description\n","\tsprintf(M->desc, \"Random mqdb:  mat. size = %d, num. blocks = %d, blk sizes: \",n,k);\n","}\n","\n","/**\n"," * rand_gen_mqdb: mqdb  type returned\n"," *                n     square matrix size\n"," *                k     number of blocks\n"," *                seed  seed for random generator\n"," */\n","mqdb genRandMat(unsigned n, unsigned k, unsigned seed) {\n","\tmqdb M;\n","\tsrand(seed);\n","\tgenRandDims(&M, n, k);\n","\tM.nBlocks = k;\n","\n","\tsrand(time(NULL));\n","\t// random fill mat entries\n","\tfillBlocks(&M, n, k, 'R', 0.0);\n","\n","\treturn M;\n","}\n","\n","/**\n"," * const_mqdb: mqdb     is the type returned\n"," *                n     is the square matrix size\n"," *                k     is the number of blocks\n"," *                seed  is the seed for random generator\n"," *                c   \tis the constant value assigned\n"," */\n","mqdb mqdbConst(uint n, uint k, uint seed, float c) {\n","\tmqdb M;\n","\tsrand(seed);\n","\tgenRandDims(&M, n, k);\n","\tM.nBlocks = k;\n","\n","\t// fill mat entries with a constant\n","\tfillBlocks(&M, n, k, 'C', c);\n","\n","\treturn M;\n","}\n","\n","/*\n"," * standard (naive) matrix product on host\n"," */\n","void matProd(mqdb A, mqdb B, mqdb C) {\n","\tint n = 0;\n","\tfor (uint i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];\n","\n","\tfor (uint r = 0; r < n; r++)\n","\t\tfor (uint c = 0; c < n; c++) {\n","\t\t\tdouble sum = 0;\n","\t\t\tfor (uint l = 0; l < n; l++){\n","\t\t\t\tdouble a = A.elem[r * n + l];\n","\t\t\t\tdouble b = B.elem[l * n + c];\n","\t\t\t\tsum += a*b;\n","\t\t\t}\n","\t\t\tC.elem[r * n + c] = (float)sum;\n","\t\t}\n","}\n","\n","/*\n"," * elementwise comparison between two mqdb\n"," */\n","void checkResult(mqdb A, mqdb B) {\n","\tdouble epsilon = 1.0E-8;\n","\tbool match = 1;\n","\tint n = 0;\n","\tfor (int i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];\n","\tfor (int i = 0; i < n * n; i++) {\n","\t\tif (fabs(A.elem[i] - B.elem[i]) > epsilon) {\n","\t\t\tmatch = 0;\n","\t\t\tprintf(\"   * Arrays do not match!\\n\");\n","\t\t\tprintf(\"     gpu: %2.2f,  host: %2.2f at current %d\\n\", A.elem[i],\n","\t\t\t\t\tB.elem[i], i);\n","\t\t\tbreak;\n","\t\t}\n","\t}\n","\tif (match)\n","\t\tprintf(\"   Arrays match\\n\\n\");\n","}\n","/*\n"," * print mqdb\n"," */\n","void mqdbDisplay(mqdb M) {\n","\tint n = 0;\n","\tprintf(\"%s\", M.desc);\n","\tfor (int j = 0; j < M.nBlocks; j++) {\n","\t\tprintf(\"%d  \", M.blkSize[j]);\n","\t\tn += M.blkSize[j];\n","\t}\n","\tprintf(\"\\n\");\n","\tfor (int j = 0; j < n * n; j++) {\n","\t\tif (M.elem[j] == 0)\n","\t\t\tprintf(\"------\");\n","\t\telse\n","\t\t\tprintf(\"%5.2f \", M.elem[j]);\n","\t\tif ((j + 1) % n == 0)\n","\t\t\tprintf(\"\\n\");\n","\t}\n","\tprintf(\"\\n\");\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"Ic7TGi3QeZny"},"source":["### ↘️ *`TODO...`*"]},{"cell_type":"markdown","metadata":{"id":"_QMShprZETnd"},"source":["Sviluppare una funzione `C` per effettuare il prodotto ottimizzato (ristretto ai soli blocchi sulla diagonale) tra due matrici $C=A*B$ ti tipo MQDB.\n","\n","**PASSI**\n","\n","1. fissare i parametri principali: `n` dimesione della matrice, `k` numero di blocchi sulla diagonale\n","2. generare matrici a caso `genRandMat(uint n, uint k, uint seed)` o con valore costante `mqdbConst(uint n, uint k, uint seed, float c)`.\n","Nota: Le dimensioni dei blocchi $k_i$, tale che $n = \\sum_{i=1}^k k_i$, viene generata a caso\n","3. Le matrici devono avere uguale dimensione (stesso lato $n$ e ugual dimensione $k_i$ dei $k$ blocchi sulla diagonale - usare stesso seed)\n","\n","<img src=\"https://github.com/giulianogrossi/imgs/blob/main/GPU/MQDB.png?raw=true\" align=\"center\" width=600px >"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3dBgacxi9qu"},"outputs":[],"source":["%%cpp -n MQDB/prod_mqdb.cpp -s xcode\n","\n","#include \"mqdb.h\"\n","\n","/*\n"," * product between mqdb matrices restricted to blocks\n"," */\n","void mqdbProd(mqdb A, mqdb B, mqdb C) {\n","\tuint n = 0;\n","\tfor (uint i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];                    // mat dim\n","\tint k = A.nBlocks;                      // num blks\n","\tint dl = 0;                             // blk left bound\n","\tint dr = 0;                             // blk left bound\n","\tfor (uint i = 0; i < k; i++) {          // loop on blks\n","\t\tdr += A.blkSize[i];                   // blk right bound\n","\t\tfor (uint r = dl; r < dr; r++) {      // scan block rows\n","\t\t\tfor (uint c = dl; c < dr; c++) {    // scan block cols\n","\t\t\t\tfloat s = 0;\n","\t\t\t\tfor (uint l = dl; l < dr; l++)\n","\t\t\t\t\ts += A.elem[r*n + l] * B.elem[c + l * n];\n","\t\t\t\tC.elem[r*n + c] = s;\n","\t\t\t}\n","\t\t}\n","\t\tdl = dr;\n","\t}\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"IO7kSHrFi9qu"},"source":["Template..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtdrHhgOcoJI"},"outputs":[],"source":["%%cpp -n MQDB/prod_mqdb.cpp -s xcode\n","\n","#include \"mqdb.h\"\n","\n","# TODO..."]},{"cell_type":"markdown","metadata":{"id":"1CSpZ6wplPmy"},"source":["Main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r19AgzDRBJh3"},"outputs":[],"source":["%%cpp -n  MQDB/main.cpp\n","#include <sys/time.h>\n","#include \"mqdb.h\"\n","\n","/*\n"," * main function\n"," */\n","int main(void) {\n","\tuint n = 2*1024;      // matrix size\n","  uint k = 10;          // num of blocks\n","\tmqdb A, B, C, C1;     // mqdb host matrices\n","\n","\t// # fill in #\n","\tA = mqdbConst(n, k, 10, 1);\n","\tB = mqdbConst(n, k, 10, 1);\n","\tC = mqdbConst(n, k, 10, 1);\n","\tC1 = mqdbConst(n, k, 10, 1);\n","\n","\tulong nBytes = n * n * sizeof(float);\n","\tulong kBytes = k * sizeof(uint);\n","\tprintf(\"Memory size required = %.1f (MB)\\n\",(float)nBytes/(1024.0*1024.0));\n","\n","\tprintf(\"CPU mat product...\\n\");\n","\tdouble start = seconds();\n","  matProd(A, B, C);\n","\tdouble CPUTime = seconds() - start;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n","\n","  printf(\"CPU MQDB product...\\n\");\n","\tstart = seconds();\n","  mqdbProd(A, B, C1);\n","\tCPUTime = seconds() - start;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n","\n","\t// check result\n","\tcheckResult(C, C1);\n","\n","\treturn 0;\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kWihzIB84j1"},"outputs":[],"source":["%%shell\n","# Compilazione ed esecuzione\n","\n","g++ MQDB/prod_mqdb.cpp MQDB/main.cpp MQDB/mqdb.cpp -o main\n","./main"]},{"cell_type":"markdown","metadata":{"id":"JrC7365ckKJ6"},"source":["## Report\n","\n","Riportare i tempi di esecuzione per\n","\n","$k = 10$\n","* n = 1024, time =\n","* n = 2048, time =\n","* n = 4096, time =\n","\n","$k = 20$\n","* n = 1024, time =\n","* n = 2048, time =\n","* n = 4096, time ="]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["9YGa6hXkx77o","F9PmBZql0ow4","227eLdP5csN1","4bll8pe7Fj3y"],"private_outputs":true,"provenance":[{"file_id":"1WU0UNEexcE6n3hufdRUgHmlSvXnClfr4","timestamp":1677494778770},{"file_id":"1IFQanBdBBUzqheWXiloaVlYrS_p2zjrL","timestamp":1677229457617}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
>>>>>>> Stashed changes
