{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1uIujYFdErtZB5zNoXUNWe38YvEQzZ3es","timestamp":1744262140449}],"collapsed_sections":["NO_C5o9-xRF_","1snOeEsH_5z3","1mcH0btsFLos","OHR7Zs3dNs1N"],"mount_file_id":"1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo","authorship_tag":"ABX9TyMXNRc6pp8Z/IQcmFjoD2KF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","# **LAB 6 - Ottimizzazione ed efficienza**\n","---"],"metadata":{"id":"fZYqN0UwVLC_"}},{"cell_type":"markdown","metadata":{"id":"NO_C5o9-xRF_"},"source":["# ▶️ CUDA setup"]},{"cell_type":"code","metadata":{"id":"8fekR2O4xRGE"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Psl9iouxRGE"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GPU computing notebooks download (from github)"],"metadata":{"id":"gcg1GyK5srek"}},{"cell_type":"code","source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"],"metadata":{"id":"tyHOxci3s3H8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"227eLdP5csN1"},"source":["NVCC Plugin for Jupyter notebook"]},{"cell_type":"code","source":["%cd GPUcomputing/utils/nvcc4jupyter-master/\n","!!python3 -m build\n","%load_ext nvcc4jupyter\n","%cd /content/"],"metadata":{"id":"4TzxMBFds8aT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUYP4kCJhEIx"},"source":["# ✅ Occupancy Calculator - DeviceQuery"]},{"cell_type":"code","metadata":{"id":"Vvl8WXljg0WK"},"source":["%%cuda\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","int main(void) {\n","\n","\tprintf(\"\\nCUDA Device Query (Runtime API) version (CUDART static linking)\\n\\n\");\n","\tint deviceCount = 0;\n","\tCHECK(cudaGetDeviceCount(&deviceCount));\n","\n","\t// This function call returns 0 if there are no CUDA capable devices.\n","\tif (deviceCount == 0)\n","\t\tprintf(\"There are no available device(s) that support CUDA\\n\");\n","\telse\n","\t\tprintf(\"Detected %d CUDA Capable device(s)\\n\", deviceCount);\n","\n","\tint dev, driverVersion = 0, runtimeVersion = 0;\n","\n","\tfor (dev = 0; dev < deviceCount; ++dev) {\n","\t\tcudaSetDevice(dev);\n","\t\tcudaDeviceProp deviceProp;\n","\t\tcudaGetDeviceProperties(&deviceProp, dev);\n","\n","\t\tprintf(\"\\nDevice %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n","\n","\t\tcudaDriverGetVersion(&driverVersion);\n","\t\tcudaRuntimeGetVersion(&runtimeVersion);\n","\n","\t\tprintf(\"  CUDA Driver Version / Runtime Version          %d.%d / %d.%d\\n\",\n","\t\t\t\tdriverVersion / 1000, (driverVersion % 100) / 10,\n","\t\t\t\truntimeVersion / 1000, (runtimeVersion % 100) / 10);\n","\n","\t\tprintf(\"  GPU arch name:                                 %s\\n\",\n","\t\t\t\t\t\t_ConvertSMVer2ArchName(deviceProp.major, deviceProp.minor));\n","\n","\t\tprintf(\"  CUDA Capability Major/Minor version number:    %d.%d\\n\",\n","\t\t\t\tdeviceProp.major, deviceProp.minor);\n","\n","\t\tprintf(\"  Total amount of global memory:                 %.0f MBytes (%llu bytes)\\n\",\n","\t\t\t\t(float) deviceProp.totalGlobalMem / 1048576.0f,\n","\t\t\t\t(unsigned long long) deviceProp.totalGlobalMem);\n","\n","\t\tprintf(\"  (%2d) Multiprocessors, (%3d) CUDA Cores/MP:     %d CUDA Cores\\n\",\n","\t\t\t\t\t\tdeviceProp.multiProcessorCount,\n","\t\t\t\t\t\t_ConvertSMVer2Cores(deviceProp.major, deviceProp.minor),\n","\t\t\t\t\t\t_ConvertSMVer2Cores(deviceProp.major, deviceProp.minor) *\n","\t\t\t\t\t\t\t\tdeviceProp.multiProcessorCount);\n","\n","\t\tprintf(\"  GPU Max Clock rate:                            %.0f MHz (%0.2f GHz)\\n\",\n","\t\t\t\tdeviceProp.clockRate * 1e-3f, deviceProp.clockRate * 1e-6f);\n","\n","\t\tprintf(\"  Memory Clock rate:                             %.0f Mhz\\n\", deviceProp.memoryClockRate * 1e-3f);\n","\t\tprintf(\"  Memory Bus Width:                              %d-bit\\n\", deviceProp.memoryBusWidth);\n","\t\tif (deviceProp.l2CacheSize)\n","\t\t\tprintf(\"  L2 Cache Size:                                 %d bytes\\n\", deviceProp.l2CacheSize);\n","\n","\t\tprintf(\"  Maximum Texture Dimension Size (x,y,z)         1D=(%d), 2D=(%d, %d), 3D=(%d, %d, %d)\\n\",\n","\t\t\t\tdeviceProp.maxTexture1D, deviceProp.maxTexture2D[0],\n","\t\t\t\tdeviceProp.maxTexture2D[1], deviceProp.maxTexture3D[0],\n","\t\t\t\tdeviceProp.maxTexture3D[1], deviceProp.maxTexture3D[2]);\n","\n","\t\tprintf(\"  Maximum Layered 1D Texture Size, (num) layers  1D=(%d), %d layers\\n\",\n","\t\t\t\tdeviceProp.maxTexture1DLayered[0],\n","\t\t\t\tdeviceProp.maxTexture1DLayered[1]);\n","\n","\t\tprintf(\"  Maximum Layered 2D Texture Size, (num) layers  2D=(%d, %d), %d layers\\n\",\n","\t\t\t\tdeviceProp.maxTexture2DLayered[0],\n","\t\t\t\tdeviceProp.maxTexture2DLayered[1],\n","\t\t\t\tdeviceProp.maxTexture2DLayered[2]);\n","\n","\t\tprintf(\"  Total amount of constant memory                %lu bytes\\n\",\n","\t\t\t\tdeviceProp.totalConstMem);\n","\t\tprintf(\"  Total amount of shared memory per block        %lu bytes\\n\",\n","\t\t\t\tdeviceProp.sharedMemPerBlock);\n","\t\tprintf(\"  Total number of registers available per block  %d\\n\",\n","\t\t\t\tdeviceProp.regsPerBlock);\n","\t\tprintf(\"  Warp size                                      %d\\n\",\n","\t\t\t\tdeviceProp.warpSize);\n","\t\tprintf(\"  Maximum number of threads per multiprocessor   %d\\n\",\n","\t\t\t\tdeviceProp.maxThreadsPerMultiProcessor);\n","\t\tprintf(\"  Maximum number of threads per block            %d\\n\",\n","\t\t\t\tdeviceProp.maxThreadsPerBlock);\n","\t\tprintf(\"  Max dimension size of a thread block (x,y,z)  (%d, %d, %d)\\n\",\n","\t\t\t\tdeviceProp.maxThreadsDim[0], deviceProp.maxThreadsDim[1],\n","\t\t\t\tdeviceProp.maxThreadsDim[2]);\n","\t\tprintf(\"  Max dimension size of a grid size    (x,y,z)  (%d, %d, %d)\\n\",\n","\t\t\t\tdeviceProp.maxGridSize[0], deviceProp.maxGridSize[1],\n","\t\t\t\tdeviceProp.maxGridSize[2]);\n","\t\tprintf(\"  Maximum memory pitch                           %lu bytes\\n\",\n","\t\t\t\tdeviceProp.memPitch);\n","\t\tprintf(\"  Texture alignment                              %lu bytes\\n\",\n","\t\t\t\tdeviceProp.textureAlignment);\n","\t\tprintf(\"  Concurrent copy and kernel execution           %s with %d copy engine(s)\\n\",\n","\t\t\t\t(deviceProp.deviceOverlap ? \"Yes\" : \"No\"),\n","\t\t\t\tdeviceProp.asyncEngineCount);\n","\t\tprintf(\"  Run time limit on kernels                      %s\\n\",\n","\t\t\t\tdeviceProp.kernelExecTimeoutEnabled ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Integrated GPU sharing Host Memory             %s\\n\",\n","\t\t\t\tdeviceProp.integrated ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Support host page-locked memory mapping        %s\\n\",\n","\t\t\t\tdeviceProp.canMapHostMemory ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Alignment requirement for Surfaces             %s\\n\",\n","\t\t\t\tdeviceProp.surfaceAlignment ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Device has ECC support                         %s\\n\",\n","\t\t\t\tdeviceProp.ECCEnabled ? \"Enabled\" : \"Disabled\");\n","\n","\t\tprintf(\"  Device supports Unified Addressing (UVA):      %s\\n\",\n","\t\t\t\tdeviceProp.unifiedAddressing ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Device PCI Domain ID / Bus ID / location ID:   %d / %d / %d\\n\",\n","\t\t\t\tdeviceProp.pciDomainID, deviceProp.pciBusID,\n","\t\t\t\tdeviceProp.pciDeviceID);\n","\t}\n","\treturn 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Several API functions exist to assist programmers in choosing thread block size and cluster size based on register and shared memory requirements.\n","\n","- `cudaOccupancyMaxActiveBlocksPerMultiprocessor`, is the occupancy calculator API that provides an **occupancy prediction based on the block size and shared memory usage** of a kernel. This function reports occupancy in terms of the number of concurrent thread blocks per multiprocessor.\n","Note that this value can be converted to other metrics. Multiplying by the number of warps per block yields the number of concurrent warps per multiprocessor; further dividing concurrent warps by max warps per multiprocessor gives the occupancy as a percentage.\n","- `cudaOccupancyMaxPotentialBlockSize` and `cudaOccupancyMaxPotentialBlockSizeVariableSMem`, are the occupancy-based launch configurator APIs, **heuristically calculate an execution configuration that achieves the maximum multiprocessor-level occupancy.**\n","- `cudaOccupancyMaxActiveClusters`, can provided occupancy prediction based on the cluster size, block size and shared memory usage of a kernel. This function reports occupancy in terms of number of max active clusters of a given size on the GPU present in the system."],"metadata":{"id":"evll6aSlzVtd"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","The following code sample calculates the occupancy of MyKernel. It then reports the occupancy level with the **ratio between concurrent warps versus maximum warps per multiprocessor**."],"metadata":{"id":"JSbDdWC3zzHX"}},{"cell_type":"code","source":["%%cuda_group_save --name \"occupancy.cu\" --group \"lez6\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","\n","// Device code\n","__global__ void MyKernel(int *d, int *a, int *b) {\n","  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","  d[idx] = a[idx] * b[idx];\n","}\n","\n","// Host code\n","int main() {\n","  device_feat();    // device feats\n","  int numBlocks;    // number of of active blocks\n","\n","  // These variables are used to convert occupancy to warps\n","  int device;\n","  cudaDeviceProp prop;\n","  int activeWarps;\n","  int maxWarps;\n","\n","  cudaGetDevice(&device);\n","  cudaGetDeviceProperties(&prop, device);\n","  maxWarps = prop.maxThreadsPerMultiProcessor / prop.warpSize;\n","\n","  for (int blockSize = 16; blockSize <= 1024; blockSize*=2) {\n","    cudaOccupancyMaxActiveBlocksPerMultiprocessor(&numBlocks, MyKernel, blockSize, 0);\n","    activeWarps = numBlocks * blockSize / prop.warpSize;\n","    double occup = (double)activeWarps / maxWarps * 100;\n","    printf(\"blockSize = %4d <-> Occupancy [numBlocks = %2d,  activeWarps = %2d]:\\t%2.2f%%\\n\", blockSize, numBlocks, activeWarps, occup);\n","  }\n","  return 0;\n","}"],"metadata":{"id":"13Kv4NcSOanG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"ctyo0LAUTyw8"}},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/lez6/occupancy.cu -o occupancy\n","!./occupancy"],"metadata":{"id":"sXoLaamxSk33"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","The following code sample configures an occupancy-based kernel launch of MyKernel according to the user input.\n"],"metadata":{"id":"JoXN6tHHz5AV"}},{"cell_type":"code","source":["%%cuda_group_save --name \"occupancy.cu\" --group \"lez6\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","\n","// Device code\n","__global__ void MyKernel(float *array, int arrayCount) {\n","  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","  if (idx < arrayCount)\n","    array[idx] *= array[idx];\n","}\n","\n","__global__ void MyKernel1(int *d, int *a, int *b) {\n","  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","  d[idx] = a[idx] * b[idx];\n","}\n","\n","// occupancy calculator\n","int occupancy(float *array, int arrayCount) {\n","  int blockSize;      // The launch configurator returned block size\n","  int minGridSize;    // The minimum grid size needed to achieve the\n","                      // maximum occupancy for a full device launch\n","  int gridSize;       // The actual grid size needed, based on input size\n","\n","  cudaOccupancyMaxPotentialBlockSize(&minGridSize, &blockSize, (void*)MyKernel, 0, arrayCount);\n","\n","  // Round up according to array size\n","  gridSize = (arrayCount + blockSize - 1) / blockSize;\n","  printf(\"blockSize = %4d, gridSize = %d, minGridSize = %2d\\n\", blockSize, gridSize, minGridSize);\n","\n","  MyKernel<<<gridSize, blockSize>>>(array, arrayCount);\n","  cudaDeviceSynchronize();\n","\n","  // compute occupancy\n","  int device;\n","  int numBlocks;\n","  cudaDeviceProp prop;\n","  cudaGetDevice(&device);\n","  cudaGetDeviceProperties(&prop, device);\n","  int maxWarps = prop.maxThreadsPerMultiProcessor / prop.warpSize;\n","  cudaOccupancyMaxActiveBlocksPerMultiprocessor(&numBlocks, MyKernel, blockSize, 0);\n","  int activeWarps = numBlocks * blockSize / 32;\n","  double occup = (double)activeWarps / maxWarps * 100;\n","  printf(\"Occupancy [blockSize = %4d, activeWarps = %2d]:\\t%2.2f%%\\n\", blockSize, activeWarps, occup);\n","\n","  return 0;\n","}\n","\n","// MAIN\n","int main(void) {\n","  device_feat();    // device feats\n","  int N = 2<<20;\n","  size_t size = N * sizeof(float);\n","\n","  // Allocate input vectors h_A and h_B in host memory\n","  float* h_A = (float*)malloc(size);\n","  float* h_B = (float*)malloc(size);\n","  float* h_C = (float*)malloc(size);\n","\n","  // Allocate vectors in device memory\n","  float* d_A;\n","  cudaMalloc(&d_A, size);\n","  float* d_B;\n","  cudaMalloc(&d_B, size);\n","  float* d_C;\n","  cudaMalloc(&d_C, size);\n","\n","  // Copy vectors from host memory to device memory\n","  cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","  cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","  // Invoke kernel\n","  occupancy(d_A, N);\n","\n","  // Free device memory\n","  cudaFree(d_A);\n","  cudaFree(d_B);\n","  cudaFree(d_C);\n","\n","  return 0;\n","}"],"metadata":{"id":"o-tdfCu8LWfM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"qD6Mt57rQFwt"}},{"cell_type":"code","source":["!nvcc -arch=sm_75  src/lez6/occupancy.cu -o occupancy\n","!./occupancy"],"metadata":{"id":"vGWag71kX1Ad"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ↘️ *`TODO...`*"],"metadata":{"id":"hlvdDnAdHaee"}},{"cell_type":"markdown","source":["Apply the same calculator to the kernel:\n","\n","```\n","__global__ void blockParReduce1(int *in, int *out, ulong n)\n","```\n","\n"],"metadata":{"id":"lv1svOfqJFPr"}},{"cell_type":"code","source":["%%cuda_group_save --name \"occupancy.cu\" --group \"lez6\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","__global__ void blockParReduce1(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","\t// in-place reduction in global memory\n","\tfor (int stride = 1; stride < blockDim.x; stride *= 2) {\n","\t\tif ((tid % (2 * stride)) == 0)\n","\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","// MAIN\n","int main(void) {\n","  int numBlocks;        // Occupancy in terms of active blocks\n","\n","  // These variables are used to convert occupancy to warps\n","\n","\t// TODO\n","\n","  return 0;\n","}"],"metadata":{"id":"8BSlGWgvHaCl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"NC8uszYhQq0I"}},{"cell_type":"code","source":["!nvcc -arch=sm_75 --ptxas-options=-v src/lez6/occupancy.cu -o occupancy\n","!./occupancy"],"metadata":{"id":"I2H9W15WYKaE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Apply the same calculator to the kernel:\n","\n","```\n","__global__ void blockParReduce_SMEM(int *in, int *out, ulong n)\n","```\n"],"metadata":{"id":"PL72zrGpYB8U"}},{"cell_type":"code","source":["%%cuda_group_save --name \"occupancy.cu\" --group \"lez6\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","#define SMEM_DIM 1024\n","\n","/*\n","    This version uses sequential addressing -- no divergence or bank conflicts.\n","*/\n","__global__ void blockParReduce_SMEM(int *in, int *out, ulong n) {\n","\n","\t// shared mem\n","\t__shared__ int smem[SMEM_DIM];\n","\n","\tunsigned int tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// load shared mem\n","\tsmem[tid] = (idx < n) ? in[idx] : 0;\n","\n","\t// synchronize within threadblock\n","\t__syncthreads();\n","\n","\t// do reduction in shared mem\n","\tfor (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n","\t\tif (tid < stride)\n","\t\t\tsmem[tid] += smem[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = smem[0];\n","}\n","\n","\n","// MAIN\n","int main(void) {\n","  int numBlocks;        // Occupancy in terms of active blocks\n","\n","  // These variables are used to convert occupancy to warps\n","\n","\t // TODO\n","\n","  return 0;\n","}"],"metadata":{"id":"2Yw-iUA9UcX0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"ZCtX8rnlQvrn"}},{"cell_type":"code","source":["!nvcc -arch=sm_75 --ptxas-options=-v src/lez6/occupancy.cu -o occupancy\n","!./occupancy"],"metadata":{"id":"Rq5tZidEYNtQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_75 --ptxas-options=-v src/lez6/occupancy.cu"],"metadata":{"id":"J6l-x5kymaN0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ✅ Profiling"],"metadata":{"id":"1snOeEsH_5z3"}},{"cell_type":"markdown","source":["### Profilazione dettagliata del filtro PPM blurring implemenato in  `ppm_blurGPU.cu`"],"metadata":{"id":"1mcH0btsFLos"}},{"cell_type":"code","source":["%%cuda_group_save --name \"ppm_blurGPU.cu\" --group \"lez6\"\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include \"ppm.h\"\n","#include \"../../GPUcomputing/utils/common.h\"\n","\n","/*\n"," * Set pel (pixel element) in ppm image.\n"," */\n"," __device__ void ppm_setGPU(PPM ppm, int x, int y, pel c) {\n","  int i = x + y*ppm.width;\n","  ppm.image[3*i] = c.r;\n","  ppm.image[3*i + 1] = c.g;\n","  ppm.image[3*i + 2] = c.b;\n","}\n","\n","/*\n","* Get pel (pixel element) from ppm image.\n","*/\n","__device__ pel ppm_getGPU(PPM ppm, int x, int y) {\n","  pel p;\n","  int i = x + y*ppm.width;\n","  p.r = ppm.image[3*i];\n","  p.g = ppm.image[3*i + 1];\n","  p.b = ppm.image[3*i + 2];\n","  return p;\n","}\n","\n","/*\n"," * Kernel 2D for PPM image blurring\n"," */\n","__global__ void ppm_blurGPU(PPM ppm, PPM ppm1, int MASK_SIZE) {\n","\n","  int x = blockIdx.x * blockDim.x + threadIdx.x;\n","  int y = blockIdx.y * blockDim.y + threadIdx.y;\n","\n","  if(x < ppm.width && y < ppm.height) {\n","    float R=0, G=0, B=0;\n","    int numPixels = 0;\n","    int RADIUS = MASK_SIZE/2;\n","    for(int r = -RADIUS; r < RADIUS; ++r) {\n","        for(int c = -RADIUS; c < RADIUS; ++c) {\n","            int row = y + r;\n","            int col = x + c;\n","            if(row > -1 && row < ppm.height && col > -1 && col < ppm.width) {\n","                int i = col + row*ppm.width;\n","                R += ppm.image[3*i];\n","                G += ppm.image[3*i + 1];\n","                B += ppm.image[3*i + 2];\n","                numPixels++;\n","            }\n","        }\n","    }\n","    int i = x + y*ppm.width;\n","    ppm1.image[3*i]     = (color)(R/numPixels);\n","    ppm1.image[3*i + 1] = (color)(G/numPixels);\n","    ppm1.image[3*i + 2] = (color)(B/numPixels);\n","  }\n","}\n","\n","/*\n"," * MAIN\n"," */\n","int main(int argc, char **argv) {\n","\n","  // PPM images\n","  PPM *ppm, *ppm1, *ppm2;  // Where images are stored in CPU\n","  PPM ppm_d, ppm1_d;\t     // Where images are stored in GPU\n","\n","  // load a PPM image from file\n","  char path[] = \"GPUcomputing/images/dog.ppm\";\n","  ppm = ppm_load(path);\n","  ppm1 = ppm_copy(ppm);\n","  uint WIDTH = ppm->width;\n","  uint HEIGHT = ppm->height;\n","  printf(\"PPM image size (w x h): %d x %d\\n\", WIDTH, HEIGHT);\n","\n","  // set main params\n","  size_t nBytes= WIDTH * HEIGHT * sizeof(pel);\n","  ppm_d.width = WIDTH;\n","  ppm_d.height = HEIGHT;\n","  ppm_d.maxval = ppm->maxval;\n","  int MASK_SIZE = 21;\n","\n","  // Allocate GPU buffer for the input and output images\n","  CHECK(cudaMalloc(&ppm_d.image, nBytes));\n","  CHECK(cudaMalloc(&ppm1_d.image, nBytes));\n","\n","  // copy image from CPU to GPU\n","  CHECK(cudaMemcpy(ppm_d.image, ppm->image, nBytes, cudaMemcpyHostToDevice));\n","\n","  // invoke kernels (define grid and block sizes)\n","  uint dimBlock = 16;\n","  dim3 block(dimBlock, dimBlock);\n","  dim3 grid((WIDTH + block.x - 1) / block.x, (HEIGHT + block.y - 1) / block.y);\n","\n","  double start = seconds();\n","  ppm_blurGPU <<<grid, block>>> (ppm_d, ppm1_d, MASK_SIZE);\n","  CHECK(cudaDeviceSynchronize());\n","  double stopGPU = seconds() - start;\n","\n","  // copy image from GPU to CPU\n","  CHECK(cudaMemcpy(ppm1->image, ppm1_d.image, nBytes, cudaMemcpyDeviceToHost));\n","  ppm_write(ppm1, \"ppm_blurredGPU.ppm\");\n","\n","  // check results with CPU\n","  ppm2 = ppm_make(ppm->width, ppm->height, (pel){0,0,0});\n","  start = seconds();\n","  ppm_blur(ppm, ppm2, MASK_SIZE);\n","  double stopCPU = seconds() - start;\n","  ppm_write(ppm2, \"ppm_blurredCPU.ppm\");\n","  printf(\"PPM images are %s\\n\", ppm_equal(ppm1, ppm2) ? \"equal\" : \"not equal\");\n","\n","  // free device memory\n","  CHECK(cudaFree(ppm_d.image));\n","  CHECK(cudaFree(ppm1_d.image));\n","\n","  // times & speedup\n","  printf(\"CPU elapsed time: %.4f (msec) \\n\", stopCPU*1000);\n","  printf(\"CPU elapsed time: %.4f (msec) - Speedup %.1f\\n\", stopGPU*1000, stopCPU/stopGPU);\n","\n","  return (EXIT_SUCCESS);\n","}\n"],"metadata":{"id":"kJyDJu7wurWA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"T9S0V6giQ1QK"}},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/lez6/ppm_blurGPU.cu -o blur -I GPUcomputing/utils/PPM  GPUcomputing/utils/PPM/ppm.cpp\n","!./blur"],"metadata":{"id":"K8YvyTng_-iC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Profiling...**"],"metadata":{"id":"-93JHCdRy3aw"}},{"cell_type":"code","source":["!ncu -f -o ppm_blurGPU_T4_profiling.ncu-rep blur"],"metadata":{"id":"XUzxfgLAycxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ncu -i blur_profiling.ncu-rep"],"metadata":{"id":"8Oxzo8_W0HWh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Profilazione dettagliata del filtro di convoluzione implemenato in `conv2D.cu`"],"metadata":{"id":"a94Iq13XGBQT"}},{"cell_type":"code","source":["%%cuda_group_save --name \"conv2D.cu\" --group \"lez6\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","#define BLOCK_SIZE   16\n","#define MASK_SIZE    21\n","#define TILE_SIZE    (BLOCK_SIZE + MASK_SIZE - 1)\n","\n","typedef struct {\n","   int width;\n","   int height;\n","   float* elements;\n"," } Matrix;\n","\n","// Function declarations\n"," void conv2D_host(Matrix A, Matrix B, Matrix M);\n","__global__ void conv2D_basic(Matrix A, Matrix B, Matrix M);\n","\n"," /*\n","  * 2D convolution using shared memory\n","  *   A: input matrix\n","  *   B: output matrix\n","  *   M: convolution mask matrix\n"," */\n","__global__ void conv2D(Matrix A, Matrix B, Matrix M) {\n","\n","   int x = blockIdx.x * blockDim.x + threadIdx.x; // Column index of matrix A\n","   int y = blockIdx.y * blockDim.y + threadIdx.y; // Row index of matrix A\n","\n","   int tile_size = BLOCK_SIZE + MASK_SIZE - 1;\n","   int radius = MASK_SIZE / 2;\n","\n","   // Allocate shared memory\n","   __shared__ float smem[TILE_SIZE][TILE_SIZE];\n","\n","   // Load data into shared memory\n","   for (int row = 0; row <= tile_size/blockDim.y; row++) {\n","      for (int col = 0; col <= tile_size/blockDim.x; col++) {\n","         int row_data = y + blockDim.y * row - radius;   // input data index row\n","         int col_data = x + blockDim.x * col - radius;   // input data index column\n","         int row_smem = threadIdx.y + blockDim.y * row;  // mask index row\n","         int col_smem = threadIdx.x + blockDim.x * col;  // mask index column\n","\n","         // Check valid range for smem and data\n","         if (row_smem < tile_size && col_smem < tile_size) {\n","            if (row_data >= 0 && row_data < A.height && col_data >= 0 && col_data < A.width) {\n","               smem[row_smem][col_smem] = A.elements[row_data * A.width + col_data];\n","            } else {\n","               smem[row_smem][col_smem] = 0.0f;\n","            }\n","         }\n","      }\n","   }\n","\n","   // Synchronize threads\n","   __syncthreads();\n","\n","   // Apply convolution\n","   float sum = 0.0f;\n","   for (int i = 0; i < MASK_SIZE; i++) {\n","      for (int j = 0; j < MASK_SIZE; j++) {\n","         int r = threadIdx.y + i;\n","         int c = threadIdx.x + j;\n","         if (r >= 0 && r < tile_size && c >= 0 && c < tile_size) {\n","            sum += smem[r][c] * M.elements[i * MASK_SIZE + j];\n","         }\n","      }\n","   }\n","\n","   // Write output\n","   if (y < A.height && x < A.width) {\n","      B.elements[y * B.width + x] = sum;\n","   }\n","}\n","\n","/*\n"," * Main function\n"," */\n","int main(void) {\n","   // define matrices and params\n","   int block_size = BLOCK_SIZE;\n","   int mask_size = MASK_SIZE;\n","   int width = 256* block_size, height = 256* block_size;\n","   Matrix A, B, H, M;\n","   A.width = width; A.height = height;\n","   B.width = width; B.height = height;\n","   M.width = mask_size; M.height = mask_size;\n","   H.width = width; H.height = height;\n","   A.elements = (float *)malloc(width * height * sizeof(float));\n","   B.elements = (float *)malloc(width * height * sizeof(float));\n","   M.elements = (float *)malloc(mask_size * mask_size * sizeof(float));\n","   H.elements = (float *)malloc(width * height * sizeof(float));\n","\n","   // Initialize A, B, M\n","   // print data sizes\n","   printf(\"Data matrix A: %d x %d\\n\", width, height);\n","   printf(\"Mask matrix M: %d x %d\\n\", mask_size, mask_size);\n","   for (int i = 0; i < width * height; i++) {\n","      A.elements[i] = 1.0f;\n","      B.elements[i] = 0.0f;\n","   }\n","   for (int i = 0; i < mask_size * mask_size; i++) {\n","      M.elements[i] = 1.0f;\n","   }\n","\n","   // Allocate device memory\n","   Matrix d_A, d_B, d_M;\n","   d_A.width = A.width; d_A.height = A.height;\n","   d_B.width = B.width; d_B.height = B.height;\n","   d_M.width = M.width; d_M.height = M.height;\n","   CHECK(cudaMalloc(&d_A.elements, width * height * sizeof(float)));\n","   CHECK(cudaMalloc(&d_B.elements, width * height * sizeof(float)));\n","   CHECK(cudaMalloc(&d_M.elements, mask_size * mask_size * sizeof(float)));\n","\n","   // Copy data to device\n","   CHECK(cudaMemcpy(d_A.elements, A.elements, width * height * sizeof(float), cudaMemcpyHostToDevice));\n","   CHECK(cudaMemcpy(d_M.elements, M.elements, mask_size * mask_size * sizeof(float), cudaMemcpyHostToDevice));\n","\n","   /***********************************************************/\n","\t/*                    conv2D on host                       */\n","\t/***********************************************************/\n","   printf(\"\\nCPU procedure...\\n\");\n","\tdouble start = seconds();\n","\tconv2D_host(A, H, M);\n","\tdouble stopCPU = seconds() - start;\n","   printf(\"   Host elapsed time: %f\\n\", stopCPU);\n","\n","   /***********************************************************/\n","\t/*                    GPU naive conv2D                     */\n","\t/***********************************************************/\n","   printf(\"\\nGPU naive conv2D...\\n\");\n","   dim3 dimBlock(block_size, block_size);\n","   dim3 dimGrid((width + block_size - 1) / block_size, (height + block_size - 1) / block_size);\n","   start = seconds();\n","   conv2D_basic<<<dimGrid, dimBlock>>>(d_A, d_B, d_M);\n","   CHECK(cudaDeviceSynchronize());\n","   double stopGPU = seconds() - start;\n","   printf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU, stopCPU / stopGPU);\n","\n","   // Copy data back to host\n","   CHECK(cudaMemcpy(B.elements, d_B.elements, width * height * sizeof(float), cudaMemcpyDeviceToHost));\n","\n","   // check results\n","   for (int i = 0; i < width; i++) {\n","      for (int j = 0; j < height; j++) {\n","         if (B.elements[j * width + i] != H.elements[j * width + i]) {\n","            printf(\"Error at B[%d][%d] = %f\\n\", i, j, B.elements[j * width + i]);\n","         }\n","      }\n","   }\n","\n","   // zero out B in device\n","   CHECK(cudaMemset(d_B.elements, 0, width * height * sizeof(float)));\n","\n","   /***********************************************************/\n","\t/*                  GPU conv2D wih smem                    */\n","\t/***********************************************************/\n","   printf(\"\\nGPU conv2D with smem...\\n\");\n","   start = seconds();\n","   conv2D<<<dimGrid, dimBlock>>>(d_A, d_B, d_M);\n","   CHECK(cudaDeviceSynchronize());\n","   stopGPU = seconds() - start;\n","   printf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU, stopCPU / stopGPU);\n","\n","   // Copy data back to host\n","   CHECK(cudaMemcpy(B.elements, d_B.elements, width * height * sizeof(float), cudaMemcpyDeviceToHost));\n","\n","   // check results\n","   for (int i = 0; i < width; i++) {\n","      for (int j = 0; j < height; j++) {\n","         if (B.elements[j * width + i] != H.elements[j * width + i]) {\n","            printf(\"Error at B[%d][%d] = %f\\n\", i, j, B.elements[j * width + i]);\n","         }\n","      }\n","   }\n","\n","   return 0;\n","}\n","\n","/*\n"," * 2D convolution on host\n"," */\n","void conv2D_host(Matrix A, Matrix B, Matrix M) {\n","\n","   int radius = MASK_SIZE / 2;\n","\n","   // loop through all elements in the output array\n","   for (int y = 0; y < A.height; y++) {\n","\t   for (int x = 0; x < A.width; x++) {\n","\t\t\tfloat sum = 0.0f;\n","\n","\t\t\t// compute convolution\n","\t\t\tfor (int i = 0; i < MASK_SIZE; i++) {\n","            for (int j = 0; j < MASK_SIZE; j++) {\n","               int r = y - radius + i;\n","\t\t\t\t\tint c = x - radius + j;\n","\n","\t\t\t\t\t//boundary check\n","\t\t\t\t\tif ((c >= 0) && (c < A.width) && (r >= 0) && (r < A.height)) {\n","\t\t\t\t\t\tsum += A.elements[(r * A.width) + c] * M.elements[(j * MASK_SIZE) + i];\n","\t\t\t\t\t}\n","\t\t\t\t}\n","         }\n","\n","         //store final value\n","         B.elements[y * B.width + x] = sum;\n","\t   }\n","   }\n","}\n","\n","/*\n"," * Basic kernel for 2D convolution\n"," */\n"," __global__ void conv2D_basic(Matrix A, Matrix B, Matrix M) {\n","\n","\t//index computation\n","\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n","\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n","   int radius = MASK_SIZE / 2;\n","\n","   //boundary check\n","   if (x >= A.width && y >= A.height)  return;\n","\n","   // Apply convolution\n","   float sum = 0.0f;\n","   for (int i = 0; i < MASK_SIZE; i++) {\n","      for (int j = 0; j < MASK_SIZE; j++) {\n","         int r = y - radius + i;\n","         int c = x - radius + j;\n","         if (r >= 0 && r < A.height && c >= 0 && c < A.width) {\n","            sum += A.elements[r * A.width + c] * M.elements[i * MASK_SIZE + j];\n","         }\n","      }\n","   }\n","\n","   //store final value\n","   B.elements[y * B.width + x] = sum;\n","}"],"metadata":{"id":"0WGt14FTGFAj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"9AhdYJUwH-wE"}},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/lez6/ppm_blurGPU.cu -o blur -I GPUcomputing/utils/PPM  GPUcomputing/utils/PPM/ppm.cpp\n","!./blur"],"metadata":{"id":"sfUMBBBiH-wF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Profiling...**"],"metadata":{"id":"mKIS9PCAH-wF"}},{"cell_type":"code","source":["!ncu -o ppm_blurGPU_T4_profiling.ncu-rep blur"],"metadata":{"id":"QnCJfdp9H-wF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ncu -i blur_profiling.ncu-rep"],"metadata":{"id":"jSRjTUqxH-wG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ✅ Parallel reduction unrolling\n","\n","\n"],"metadata":{"id":"OHR7Zs3dNs1N"}},{"cell_type":"markdown","source":["↘️ **TODO...**"],"metadata":{"id":"1wm23k6-G38i"}},{"cell_type":"markdown","source":["Kernel privo di divergenza + unrolling:\n","\n","* Introdurre warp unrolling\n","* Introdurre block unrolling\n","* Specializzare su diversi num blocchi\n","* Confrontare i vari kernel...\n","\n","\n"],"metadata":{"id":"WK1z7xCcSz5v"}},{"cell_type":"code","source":["%%cuda_group_save --name \"preduceUnroll.cu\" --group \"lez6\"\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <assert.h>\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","#define SMEM_DIM 1024\n","\n","/*\n","*  Block by block parallel implementation with divergence (sequential schema)\n","*/\n","__global__ void blockParReduce1(int *in, int *out, ulong n) {\n","\n","\tint tid = threadIdx.x;\n","\tint idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","\t// in-place reduction in global memory\n","\tfor (int stride = 1; stride < blockDim.x; stride *= 2) {\n","\t\tif ((tid % (2 * stride)) == 0)\n","\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","/*\n","*  Block by block parallel implementation without divergence (interleaved schema)\n","*/\n","__global__ void blockParReduce2(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","\t// in-place reduction in global memory\n","\tfor (int stride = blockDim.x / 2; stride > 0; stride >>= 1)  {\n","\t\tif (tid < stride)\n","\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","/*\n","* Using shared memory (no divergence nor bank conflicts)\n","*/\n","__global__ void blockParReduce3(int *in, int *out, ulong n) {\n","\n","\t// shared mem\n","\t__shared__ int smem[SMEM_DIM];\n","\n","\tunsigned int tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// load shared mem\n","\tsmem[tid] = (idx < n) ? in[idx] : 0;\n","\n","\t// synchronize within threadblock\n","\t__syncthreads();\n","\n","\t// do reduction in shared mem\n","\tfor (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n","\t\tif (tid < stride)\n","\t\t\tsmem[tid] += smem[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = smem[0];\n","}\n","\n","/*\n","*  Block by block parallel implementation using warp reduction\n","*/\n","__global__ void blockParReduce4(int *in, int *out, ulong n) {\n","\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n","\tint lane = threadIdx.x % warpSize;\n","\tint wid = threadIdx.x / warpSize;\n","\n","\tstatic __shared__ int shared[32];  \t// Shared mem for 32 partial sums\n","\tint val = in[tid];  \t\t\t\t\t\t// Each thread reads one element\n","\n","\t// 1° warp-shuffle reduction\n","\tfor (int offset = warpSize/2; offset > 0; offset /= 2)\n","\t\tval += __shfl_down_sync(0xffffffff, val, offset, 32);\n","\n","\tif (lane==0) shared[wid] = val; \t// Write reduced value to shared memory\n","\n","\t__syncthreads();          \t\t\t// Wait for all partial reductions\n","\n","\t// hereafter, just warp 0 (final warp-shuffle reduction)\n","\tif (wid == 0){\n","\t\tint val = shared[lane];\n","\n","\t\tfor (int offset = warpSize/2; offset > 0; offset >>= 1)\n","\t\t\tval += __shfl_down_sync(0xffffffff, val, offset);\n","\n","\t\t\t// write result for this block to global mem\n","\t\tif (threadIdx.x == 0)\n","\t\t\tout[blockIdx.x] = val;\n","\t}\n","}\n","\n","/*\n","*  Warp reduction using shared memory\n","*/\n","__device__ void warpReduce(volatile int *smem, unsigned int tid) {\n","   smem[tid] += smem[tid+32];\n","   smem[tid] += smem[tid+16];\n","   smem[tid] += smem[tid+8];\n","   smem[tid] += smem[tid+4];\n","   smem[tid] += smem[tid+2];\n","   smem[tid] += smem[tid+1];\n"," }\n","\n","/*\n","*  Block reduction using shared memory\n","*/\n","__device__ void blockReduce(volatile int *smem, unsigned int tid) {\n","   // block in-place reduction in shared memory\n","   if (blockDim.x >= 1024 && tid < 512) smem[tid] += smem[tid + 512];\n","   __syncthreads();\n","\n","   if (blockDim.x >= 512 && tid < 256) smem[tid] += smem[tid + 256];\n","   __syncthreads();\n","\n","   if (blockDim.x >= 256 && tid < 128) smem[tid] += smem[tid + 128];\n","   __syncthreads();\n","\n","   if (blockDim.x >= 128 && tid < 64)  smem[tid] += smem[tid + 64];\n","   __syncthreads();\n","\n","   // unrolling warp\n","   if (tid < 32) warpReduce(smem, tid);\n","}\n","\n","/*\n","*  Block by block parallel implementation using complete unroll for loop + smem\n","*/\n","__global__ void blockParReduce5(int *in, int *out, int n) {\n","   // SMEM for each block\n","   static __shared__ int smem[SMEM_DIM];\n","\n","   // set thread ID\n","   int tid = threadIdx.x;\n","\n","   // boundary check\n","   int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","   if (idx >= n) return;\n","\n","   // convert global data pointer to the local pointer of this block\n","   int *idata = in + blockIdx.x * blockDim.x;\n","\n","   // set to smem by each threads\n","   smem[tid] = idata[tid];\n","   __syncthreads();\n","\n","   // block in-place reduction in shared memory\n","   blockReduce(smem, tid);\n","\n","   // write result for this block to global mem\n","   if (tid == 0) out[blockIdx.x] = smem[0];\n","}\n","\n","/*\n"," *  Multi block parallel implementation with block and warp unrolling\n"," */\n"," __global__ void blockParReduce6(int *in, int *out, ulong n) {\n","\n","   // TODO\n","\n","}\n","\n","/*\n","* MAIN: test on parallel reduction\n","*/\n","int main() {\n","\tint *a, *b, *d_a, *d_b;\n","\tint blockSize = 1024;             // block dim 1D\n","\tsize_t numBlock = 1024*1024;      // grid dim 1D\n","\tsize_t n = blockSize * numBlock;  // array dims\n","\tsize_t sum_CPU = 0, sum_GPU = 0;\n","\tsize_t nByte = n*sizeof(int);\n","\tsize_t mByte = numBlock * sizeof(int);\n","\tdouble start, stopGPU, stopCPU, speedup;\n","\n","\tprintf(\"\\n****  test on parallel reduction  ****\\n\");\n","\n","\t// init\n","\ta = (int *) malloc(nByte);\n","\tb = (int *) malloc(mByte);\n","\tfor (size_t i = 0; i < n; i++) a[i] = 1;  // initialize a[] = 1\n","\n","\tCHECK(cudaMalloc(&d_a, nByte));\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc(&d_b, mByte));\n","\tCHECK(cudaMemset(d_b, 0, mByte));\n","\n","\t/***********************************************************/\n","\t/*                     CPU reduction                       */\n","\t/***********************************************************/\n","\tprintf(\"  Vector length: %.2f MB\\n\",n/(1024.0*1024.0));\n","\tprintf(\"\\n  CPU procedure...\\n\");\n","\tstart = seconds();\n","\tfor (ulong i = 0; i < n; i++)\n","\tsum_CPU += a[i];\n","\tstopCPU = seconds() - start;\n","\tprintf(\"    Elapsed time: %f (sec) \\n\", stopCPU);\n","\tprintf(\"    sum: %lu\\n\",sum_CPU);\n","\n","\tprintf(\"\\n  GPU kernels (mem required %lu bytes)\\n\", nByte);\n","\n","\t/***********************************************************/\n","\t/*         KERNEL blockParReduce1 (divergent)              */\n","\t/***********************************************************/\n","\t// block by block parallel implementation with divergence\n","\tprintf(\"\\n  Launch kernel: blockParReduce1...\\n\");\n","\tstart = seconds();\n","\tblockParReduce1<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaGetLastError());\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\n","\t// memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++) sum_GPU += b[i];\n","\tassert(sum_GPU == n);\n","\n","\t// copy and reset vectors on GPU\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemset(d_b, 0, mByte));\n","\n","\t/***********************************************************/\n","\t/*        KERNEL blockParReduce2  (non divergent)          */\n","\t/***********************************************************/\n","\t// block by block parallel implementation without divergence\n","\tprintf(\"\\n  Launch kernel: blockParReduce2...\\n\");\n","\tstart = seconds();\n","\tblockParReduce2<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\tCHECK(cudaGetLastError());\n","\n","\t// memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++) sum_GPU += b[i];\n","\tassert(sum_GPU == n);\n","\n","\t// copy and reset vectors on GPU\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemset(d_b, 0, mByte));\n","\n","\t/***********************************************************/\n","\t/*           KERNEL blockParReduce3 (with smem)            */\n","\t/***********************************************************/\n","\t// block by block parallel implementation using warp reduction\n","\tprintf(\"\\n  Launch kernel: blockParReduce3...\\n\");\n","\tstart = seconds();\n","\tblockParReduce3<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU, speedup);\n","\tCHECK(cudaGetLastError());\n","\n","\t// memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++) sum_GPU += b[i];\n","\tassert(sum_GPU == n);\n","\n","\t// copy and reset vectors on GPU\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemset(d_b, 0, mByte));\n","\n","\t/***********************************************************/\n","\t/*        KERNEL blockParReduce4  (warp reducton)          */\n","\t/***********************************************************/\n","\t// block by block parallel implementation with smem\n","\tprintf(\"\\n  Launch kernel: blockParReduce4...\\n\");\n","\tstart = seconds();\n","\tblockParReduce4<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU, speedup);\n","\tCHECK(cudaGetLastError());\n","\n","\t// memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++) {\n","\t\tsum_GPU += b[i];\n","\t\t//printf(\"b[%d] = %d\\n\",i,b[i]);\n","\t}\n","\tassert(sum_GPU == n);\n","\n","\t// copy and reset vectors on GPU\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemset(d_b, 0, mByte));\n","\n","   /***********************************************************/\n","\t/*           KERNEL blockParReduce5  (unroll)              */\n","\t/***********************************************************/\n","\t// block by block parallel implementation with unroll + smem\n","\tprintf(\"\\n  Launch kernel: blockParReduce5...\\n\");\n","\tstart = seconds();\n","\tblockParReduce5<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU, speedup);\n","\tCHECK(cudaGetLastError());\n","\n","\t// memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++) {\n","\t\tsum_GPU += b[i];\n","\t\t//printf(\"b[%d] = %d\\n\",i,b[i]);\n","\t}\n","\tassert(sum_GPU == n);\n","\n","\t// copy and reset vectors on GPU\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemset(d_b, 0, mByte));\n","\n","   /***********************************************************/\n","\t/*         KERNEL blockParReduce6  (bock unroll)           */\n","\t/***********************************************************/\n","\t// block by block parallel implementation with unroll + smem\n","\tprintf(\"\\n  Launch kernel: blockParReduce6...\\n\");\n","\tstart = seconds();\n","\tblockParReduce6<<<numBlock/8, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU, speedup);\n","\tCHECK(cudaGetLastError());\n","\n","\t// memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++) {\n","\t\tsum_GPU += b[i];\n","\t\t//printf(\"b[%d] = %d\\n\",i,b[i]);\n","\t}\n","\tassert(sum_GPU == n);\n","\n","\tcudaFree(d_a);\n","\treturn 0;\n","}"],"metadata":{"id":"at7HdfGfkzdw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_70 src/preduceUnroll.cu -o preduceUnroll\n","!./preduceUnroll"],"metadata":{"id":"9u9U4XHAncOe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOFMQZAkjlLW"},"source":["# ✅ Parallelismo dinamico"]},{"cell_type":"code","source":["%%cuda --name nestedHelloWorld.cu\n","#include <stdio.h>\n","\n","/*\n"," * A simple example of nested kernel launches from the GPU. Each thread displays\n"," * its information when execution begins, and also diagnostics when the next\n"," * lowest nesting layer completes.\n"," */\n","\n","__global__ void nestedHelloWorld(int const iSize, int iDepth) {\n","\tint tid = threadIdx.x;\n","\tprintf(\"Recursion=%d: Hello World from thread %d block %d\\n\", iDepth, tid,\tblockIdx.x);\n","\n","\t// condition to stop recursive execution\n","\tif (iSize == 1)\n","\t\treturn;\n","\n","\t// reduce block size to half\n","\tint nthreads = iSize >> 1;\n","\n","\n","\t// thread 0 launches child grid recursively\n","\tif (tid == 0 && nthreads > 0) {\n","\t\tnestedHelloWorld<<<gridDim.x, nthreads>>>(nthreads, ++iDepth);\n","\t\tprintf(\"-------> nested execution depth: %d\\n\", iDepth);\n","\t}\n","}\n","\n","int main(int argc, char **argv) {\n","\tint size = 8;\n","\tint blocksize = 8;   // initial block size\n","\tint igrid = 2;\n","\n","\tsize = igrid * blocksize;\n","\n","\tdim3 block(blocksize, 1);\n","\tdim3 grid((size + block.x - 1) / block.x, 1);\n","\tprintf(\"%s Execution Configuration: grid %d block %d\\n\", argv[0], grid.x,\n","\t\t\tblock.x);\n","\n","\tnestedHelloWorld<<<grid, block>>>(block.x, 0);\n","\n","\tcudaDeviceReset();\n","\treturn 0;\n","}"],"metadata":{"id":"WJQmiG5fyEqy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"lip8_s9FRFd8"}},{"cell_type":"code","source":["!nvcc -arch=sm_70 -dc src/nestedHelloWorld.cu\n","!nvcc -arch=sm_70 *.o -o nestedHelloWorld\n","!./nestedHelloWorld\n"],"metadata":{"id":"F4AkCagXzdAF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Introdurre il parallelismo dinamico nel calcolo di prodotti MQDB"],"metadata":{"id":"VR2PLOEZz4fD"}},{"cell_type":"code","metadata":{"id":"QVQVpcvKjkIk"},"source":["%%cuda --name MQDB-CUDA-DP.cu\n","\n","#include \"mqdb.h\"\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define BLOCK_SIZE 16     // block size\n","\n","struct tms {\n","\tdouble GPUtmsMQDB;\n","\tdouble GPUtmsMQDBDynPar1;\n","\tdouble GPUtmsMQDBDynPark;\n","\tfloat density;\n","};\n","\n","// the kernels prototype\n","__global__ void mqdbBlockProd(mqdb, mqdb, mqdb, uint, uint, uint);\n","__global__ void mqdbProdDP1(mqdb, mqdb, mqdb, uint, uint);\n","__global__ void mqdbProdDPk(mqdb, mqdb, mqdb, uint);\n","\n","/*\n"," * Test on MQDB kernels\n"," */\n","void testKernelsMQDB(uint n, uint k, struct tms* times) {\n","\n","\t// mqdb host matrices\n","\tmqdb A, B, C, C1;\n","\n","\t// mqdb device matrices\n","\tmqdb d_A, d_B, d_C;\n","\n","\t// fill in\n","\tA = mqdbConst(n, k, 10, 1);\n","\tB = mqdbConst(n, k, 10, 1);\n","\tC = mqdbConst(n, k, 10, 1);\n","\tC1 = mqdbConst(n, k, 10, 1);\n","\n","\tulong nBytes = n * n * sizeof(float);\n","\tulong kBytes = k * sizeof(uint);\n","\tprintf(\"Memory size required = %.1f (MB)\\n\",(float)nBytes/(1024.0*1024.0));\n","\n","\t// malloc and copy on device memory\n","\td_A.nBlocks = A.nBlocks;\n","\tCHECK(cudaMalloc((void**)&d_A.blkSize, kBytes));\n","\tCHECK(cudaMemcpy(d_A.blkSize, A.blkSize, kBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void**)&d_A.elem, nBytes));\n","\tCHECK(cudaMemcpy(d_A.elem, A.elem, nBytes, cudaMemcpyHostToDevice));\n","\td_B.nBlocks = B.nBlocks;\n","\tCHECK(cudaMalloc((void**)&d_B.blkSize, kBytes));\n","\tCHECK(cudaMemcpy(d_B.blkSize, B.blkSize, kBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void**)&d_B.elem, nBytes));\n","\tCHECK(cudaMemcpy(d_B.elem, B.elem, nBytes, cudaMemcpyHostToDevice));\n","\td_C.nBlocks = C.nBlocks;\n","\tCHECK(cudaMalloc((void**)&d_C.blkSize, kBytes));\n","\tCHECK(cudaMemcpy(d_C.blkSize, C.blkSize, kBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void**)&d_C.elem, nBytes));\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\n","\t/***********************************************************/\n","\t/*                     GPU MQDB product                    */\n","\t/***********************************************************/\n","\tprintf(\"Kernel MQDB product...\\n\");\n","\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n","\tdim3 grid((n + block.x - 1) / block.x, (n + block.y - 1) / block.y);\n","\tuint sdim = 0;\n","\tdouble start = seconds();\n","\tfor (uint i = 0; i < k; i++ ) {\n","\t\tuint d = A.blkSize[i];\n","\t\tmqdbBlockProd<<<grid, block>>>(d_A, d_B, d_C, sdim, d, n);\n","\t\tsdim += d;\n","\t}\n","\tCHECK(cudaDeviceSynchronize());\n","\tdouble GPUtime2 = seconds() - start;\n","\tprintf(\"   elapsed time:                    %.2f (sec)\\n\", GPUtime2);\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n","\tcheckResult(C,C1);\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\n","\t/***********************************************************/\n","\t/*              GPU MQDB dynamic par. GRID(1)              */\n","\t/***********************************************************/\n","\tstart = seconds();\n","\tprintf(\"Kernel MQDB product with dynamic parall. GRID(1)...\\n\");\n","\n","\t\t// TODO\n","\n","\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n","\tcheckResult(C,C1);\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\n","\t/***********************************************************/\n","\t/*              GPU MQDB dynamic par. GRID(k)              */\n","\t/***********************************************************/\n","\tstart = seconds();\n","\tprintf(\"Kernel MQDB product with dynamic parall. GRID(k)...\\n\");\n","\n","\t\t// TODO\n","\n","\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n","\tcheckResult(C,C1);\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\n","\tCHECK(cudaFree(d_A.elem));\n","\tCHECK(cudaFree(d_B.elem));\n","\tCHECK(cudaFree(d_C.elem));\n","\n","\t// collect times\n","\ttimes->GPUtmsMQDB = GPUtime2;\n","\ttimes->GPUtmsMQDBDynPar1 = GPUtime3;\n","\ttimes->GPUtmsMQDBDynPark = GPUtime4;\n","\tfloat den = 0;\n","\tfor (uint j = 0; j < k; j++)\n","\t\tden += A.blkSize[j]*A.blkSize[j];\n","\ttimes->density = den/(n*n);\n","}\n","\n","/*\n"," * main function\n"," */\n","int main(int argc, char *argv[]) {\n","\tuint n = 16*1024;      // matrix size\n","\tuint min_k = 10;       // max num of blocks\n","\tuint max_k = 20;       // max num of blocks\n","\n","\tstruct tms times[max_k-min_k+1];\n","\n","\t// multiple tests on kernels\n","\tfor (uint k = min_k; k <= max_k; k++) {\n","\t\tprintf(\"\\n*****   k = %d --- (avg block size = %f)\\n\",k,(float)n/k);\n","\t\ttestKernelsMQDB(n, k, &times[k-min_k]);\n","\t}\n","\n","\tFILE *fd;\n","\tfd = fopen(\"res.csv\", \"w\");\n","\tif (fd == NULL) {\n","\t\tperror(\"file error!\\n\");\n","\t\texit(1);\n","\t}\n","\n","\t// write results on file\n","\tfprintf(fd,\"num blocks,\");\n","\t\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\t\tfprintf(fd,\"%d,\",j+min_k);\n","\n","\tfprintf(fd,\"\\nKernel MQDB product,\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsMQDB);\n","\n","\tfprintf(fd,\"\\nKernel MQDB product with dynamic parall. GRID(1),\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsMQDBDynPar1);\n","\n","\tfprintf(fd,\"\\nKernel MQDB product with dynamic parall. GRID(k),\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsMQDBDynPark);\n","\n","\tfprintf(fd,\"\\ndensity,\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].density);\n","\n","\tfclose(fd);\n","\n","\treturn 0;\n","}\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"5RRffIPhRKAw"}},{"cell_type":"code","source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_70 -dc src/MQDB-CUDA-DP.cu GPUcomputing/lab1/MQDB/mqdb.cpp\n","!nvcc -arch=sm_70 MQDB-CUDA-DP.o mqdb.o -o mqdb_prod\n","!rm -rf *.o\n","!./mqdb_prod"],"metadata":{"id":"_ci8xYBY2oSM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ↘️ *`TODO...`*"],"metadata":{"id":"Z2o3XANQf6Zv"}},{"cell_type":"code","metadata":{"id":"v9nRkLgeB10A"},"source":["%%cuda --name mqdb_DP.cu\n","\n","#include \"../../utils/MQDB/mqdb.h\"\n","\n","#define BLOCK_SIZE 16     // block size\n","\n","\n","/*\n"," * Kernel for block sub-matrix product of mqdb\n"," */\n","__global__ void mqdbBlockProd(mqdb A, mqdb B, mqdb C, uint sdim, uint d, uint n) {\n","\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// jump to the right block sub-matrix\n","\tint  offset = (n+1)*sdim;\n","\n","\t// each thread computes an entry of the product matrix\n","\tif ((row < d) && (col < d)) {\n","\t\tfloat val = 0;\n","\n","\t\tfor (int k = 0; k < d; k++)\n","\t\t\tval += A.elem[row * n + k + offset] * B.elem[k * n + col + offset];\n","\t\tC.elem[row * n + col + offset] = val;\n","\t}\n","}\n","\n","/*\n"," * Kernel for block sub-matrix product of mqdb: parent grid(1)\n"," */\n","__global__ void mqdbProdDP1(mqdb A, mqdb B, mqdb C, uint k, uint n) {\n","\n","\t// TODO\n","\n","}\n","\n","/*\n"," * Kernel for block sub-matrix product of mqdb: parent grid(k)\n"," */\n","__global__ void mqdbProdDPk(mqdb A, mqdb B, mqdb C, uint n) {\n","\n","\t// TODO\n","\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"0VXmW46URK4n"}},{"cell_type":"code","metadata":{"id":"wLxZjCx8bT3s"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_37 -dc MQDB-CUDA-DP/mqdb_DP.cu MQDB-CUDA-DP/main.cu ../utils/MQDB/mqdb.cpp\n","!nvcc -arch=sm_37 mqdb_DP.o main.o mqdb.o -o mqdb_prod\n","!rm -rf *.o\n","!./mqdb_prod"],"execution_count":null,"outputs":[]}]}