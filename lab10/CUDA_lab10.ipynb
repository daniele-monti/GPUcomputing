{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["NO_C5o9-xRF_","0_MA2agNce7T","vXUIQkZLCTcG","VjCsAmtSffwB","Y3--q4d2WgYC"],"gpuType":"T4","authorship_tag":"ABX9TyP+KqJ+LFuZef0vDiSMwv+7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","# **LAB 10 - Parallel patterns**\n","---"],"metadata":{"id":"fZYqN0UwVLC_"}},{"cell_type":"markdown","metadata":{"id":"NO_C5o9-xRF_"},"source":["# ▶️ CUDA setup"]},{"cell_type":"code","metadata":{"id":"8fekR2O4xRGE"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Psl9iouxRGE"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GPU computing notebooks download (from github)"],"metadata":{"id":"gcg1GyK5srek"}},{"cell_type":"code","source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"],"metadata":{"id":"tyHOxci3s3H8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"227eLdP5csN1"},"source":["NVCC Plugin for Jupyter notebook"]},{"cell_type":"code","source":["%cd GPUcomputing/utils/nvcc4jupyter-master/\n","!!python3 -m build\n","%load_ext nvcc4jupyter\n","%cd /content/"],"metadata":{"id":"4TzxMBFds8aT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ✅ scan"],"metadata":{"id":"0_MA2agNce7T"}},{"cell_type":"markdown","source":["↘️ **SOL...**"],"metadata":{"id":"MJeV16a6xcn8"}},{"cell_type":"code","source":["%%cuda_group_save --name \"scan.cu\" --group \"lab10\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","\n","#include \"../../GPUcomputing/utils/common.h\"\n","\n","#define BLOCK_SIZE 32\n","\n","__global__ void block_scan(int *input, int *output) {\n","   __shared__ int smem[BLOCK_SIZE];\n","   int tid = threadIdx.x;\n","\n","   // Load input into shared memory\n","   smem[tid] = input[tid];\n","   __syncthreads();\n","\n","   // Perform an inclusive scan within the block\n","   // Each thread adds the value from a previous offset (d) to its current value in SMEM\n","   for (int d = 1; d < BLOCK_SIZE; d *= 2) {\n","      if (tid >= d)\n","         smem[tid] += smem[tid - d];\n","      __syncthreads();\n","   }\n","\n","   // Write the result back to global memory\n","   output[tid] = smem[tid];\n","}\n","\n","\n","__global__ void block_scan_we(int *input, int *output) {\n","  __shared__ int smem[BLOCK_SIZE];\n","  int tid = threadIdx.x;\n","  int tid_odd = tid * 2;\n","\n","   // load input into shared memory\n","\tsmem[tid_odd] = input[tid_odd];          // odd indexed elements\n","\tsmem[tid_odd + 1] = input[tid_odd + 1];  // even indexed elements\n","\n","\tint offset = 1;\n","  // build sum in place up the tree (on SMEM)\n","\tfor (int d = BLOCK_SIZE/2; d > 0; d >>= 1) {\n","    __syncthreads();\n","\t\tif (tid < d) {\n","      int L = offset * (tid_odd + 1) - 1;\n","\t\t\tint R = offset * (tid_odd + 2) - 1;\n","\t\t\tsmem[R] += smem[L];\n","\t\t}\n","\t\toffset *= 2;\n","\t}\n","\n","  // save & clear the last element\n","  int last_elem;\n","\tif (tid == BLOCK_SIZE/2-1) {\n","    last_elem = smem[BLOCK_SIZE - 1];\n","    smem[BLOCK_SIZE - 1] = 0;      // exclusive scan\n","   }\n","\n","   // traverse down tree again to get the prefix sums\n","\tfor (int d = 1; d < BLOCK_SIZE; d *= 2) {\n","      offset >>= 1;\n","\t\t__syncthreads();\n","\t\tif (tid < d) {\n","      int L = offset * (tid_odd + 1) - 1;\n","\t\t\tint R = offset * (tid_odd + 2) - 1;\n","\t\t\tint t = smem[L];\n","\t\t\tsmem[L] = smem[R];\n","\t\t\tsmem[R] += t;\n","\t\t}\n","\t}\n","\t__syncthreads();\n","\n","  // write results to device memory\n","  if (tid < (BLOCK_SIZE/2-1)) {\n","    output[tid_odd] = smem[tid_odd + 1];\n","    output[tid_odd + 1] = smem[tid_odd + 2];\n","  }\n","  else {\n","    output[tid_odd] = smem[tid_odd + 1];\n","    output[tid_odd + 1] = last_elem; // last element\n","  }\n","}\n","\n","// Kernel to perform exclusive scan\n","// using shared memory\n","int main() {\n","  int N = BLOCK_SIZE;         // Number of elements\n","  int *in = new int[N];\n","  int *out = new int[N];\n","  int *out_cpu = new int[N];\n","\n","  // Initialize input array\n","\tfor (int i = 0; i < N; i++)\n","    in[i] = 1;\n","\n","  // cpu scan for verification\n","  out_cpu[0] = in[0];\n","  for (int i = 1; i < N; i++)\n","    out_cpu[i] = out_cpu[i-1] + in[i];\n","\n","\n","  // Allocate device memory\n","  int *d_out, *d_in;\n","\tconst int arraySize = N * sizeof(int);\n","\tcudaMalloc(&d_out, arraySize);\n","\tcudaMalloc(&d_in, arraySize);\n","\tcudaMemcpy(d_in, in, arraySize, cudaMemcpyHostToDevice);\n","\n","\t// start timer for kernel execution\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","  /***********************************************************/\n","\t/*                block_scan kernel                        */\n","\t/***********************************************************/\n","\n","  cudaEventRecord(start);\n","  block_scan<<< 1, BLOCK_SIZE>>>(d_in, d_out);\n","  cudaEventRecord(stop);\n","  cudaEventSynchronize(stop);\n","  float elapsedTime = 0;\n","  cudaEventElapsedTime(&elapsedTime, start, stop);\n","  printf(\" block_scan elaps time: %f ms\\n\", elapsedTime);\n","  cudaMemset(d_out, 0, arraySize); // clear output buffer\n","\n","  /***********************************************************/\n","\t/*               block_scan work eff. kernel               */\n","\t/***********************************************************/\n","\n","  cudaEventRecord(start);\n","  block_scan_we<<< 1, BLOCK_SIZE/2>>>(d_in, d_out);\n","  cudaEventRecord(stop);\n","  cudaEventSynchronize(stop);\n","  float elapsedTime1 = 0;\n","  cudaEventElapsedTime(&elapsedTime1, start, stop);\n","  printf(\" block_scan w.e. elaps time: %f ms\\n\", elapsedTime1);\n","\n","  // Copy result back to host\n","  cudaMemcpy(out, d_out, arraySize, cudaMemcpyDeviceToHost);\n","\n","  // check results\n","  for (int i = 0; i < N; i++) {\n","    if (out[i] != out_cpu[i]) {\n","        printf(\"Error: out[%d] = %d, expected %d\\n\", i, out[i], out_cpu[i]);\n","        break;\n","    }\n","  }\n","  printf(\"Results are correct!\\n\");\n","\n","\tcudaFree(d_out);\n","\tcudaFree(d_in);\n","\tcudaEventDestroy(start);\n","\tcudaEventDestroy(stop);\n","\n","   return 0;\n","}"],"metadata":{"id":"rK5tlPtmt4wl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↘️ **TODO...**"],"metadata":{"id":"n_0p3NPZxiZB"}},{"cell_type":"code","source":["#include <stdlib.h>\n","#include <stdio.h>\n","\n","#define BLOCK_SIZE 32\n","\n","__global__ void block_scan(int *input, int *output) {\n","   __shared__ int smem[BLOCK_SIZE];\n","   int tid = threadIdx.x;\n","\n","   // Load input into shared memory\n","   smem[tid] = input[tid];\n","   __syncthreads();\n","\n","   // Perform an inclusive scan within the block\n","   // Each thread adds the value from a previous offset (d) to its current value in SMEM\n","   for (int d = 1; d < BLOCK_SIZE; d *= 2) {\n","      if (tid >= d)\n","         smem[tid] += smem[tid - d];\n","      __syncthreads();\n","   }\n","\n","   // Write the result back to global memory\n","   output[tid] = smem[tid];\n","}\n","\n","\n","__global__ void block_scan_we(int *input, int *output) {\n","\n","   // load input into shared memory\n","\n","   // build sum in place up the tree (on SMEM)\n","\n","   // save & clear the last element\n","\n","   // traverse down tree again to get the prefix sums\n","\n","   // write results to device memory\n","\n","}\n","\n","// Kernel to perform exclusive scan\n","// using shared memory\n","int main() {\n","  int N = BLOCK_SIZE;         // Number of elements\n","  int *in = new int[N];\n","  int *out = new int[N];\n","  int *out_cpu = new int[N];\n","\n","  // Initialize input array\n","  for (int i = 0; i < N; i++)\n","    in[i] = 1;\n","\n","  // cpu scan for verification\n","  double start = seconds();\n","  out_cpu[0] = in[0];\n","  for (int i = 1; i < N; i++)\n","    out_cpu[i] = out_cpu[i-1] + in[i];\n","  double stopCPU = seconds() - start;\n","  printf(\"   Host elapsed time: %f\\n\", stopCPU);\n","\n","  // Allocate device memory\n","  int *d_out, *d_in;\n","\tconst int arraySize = N * sizeof(int);\n","\tcudaMalloc(&d_out, arraySize);\n","\tcudaMalloc(&d_in, arraySize);\n","\tcudaMemcpy(d_in, in, arraySize, cudaMemcpyHostToDevice);\n","\n","\t// start timer for kernel execution\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","  /***********************************************************/\n","\t/*                block_scan kernel                        */\n","\t/***********************************************************/\n","\n","  cudaEventRecord(start);\n","  block_scan<<< 1, BLOCK_SIZE>>>(d_in, d_out);\n","  cudaEventRecord(stop);\n","  cudaEventSynchronize(stop);\n","  float elapsedTime = 0;\n","  cudaEventElapsedTime(&elapsedTime, start, stop);\n","  printf(\" block_scan elaps time: %f ms\\n\", elapsedTime);\n","  cudaMemset(d_out, 0, arraySize); // clear output buffer\n","\n","  /***********************************************************/\n","\t/*               block_scan work eff. kernel               */\n","\t/***********************************************************/\n","\n","  cudaEventRecord(start);\n","  block_scan_we<<< 1, BLOCK_SIZE/2>>>(d_in, d_out);\n","  cudaEventRecord(stop);\n","  cudaEventSynchronize(stop);\n","  float elapsedTime1 = 0;\n","  cudaEventElapsedTime(&elapsedTime1, start, stop);\n","  printf(\" block_scan w.e. elaps time: %f ms\\n\", elapsedTime1);\n","\n","  // Copy result back to host\n","  cudaMemcpy(out, d_out, arraySize, cudaMemcpyDeviceToHost);\n","\n","  // check results\n","  for (int i = 0; i < N; i++) {\n","      if (out[i] != out_cpu[i]) {\n","        printf(\"Error: out[%d] = %d, expected %d\\n\", i, out[i], out_cpu[i]);\n","        break;\n","      }\n","  }\n","  printf(\"Results are correct!\\n\");\n","\n","\tcudaFree(d_out);\n","\tcudaFree(d_in);\n","\tcudaEventDestroy(start);\n","\tcudaEventDestroy(stop);\n","\n","   return 0;\n","}"],"metadata":{"id":"qTGerQnoxZjg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"lATlmplZxpYf"}},{"cell_type":"code","metadata":{"id":"J2kIH_YwxpYf"},"source":["!nvcc -arch=sm_75 src/lab10/scan.cu -o scan\n","!./scan"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vXUIQkZLCTcG"},"source":["# ✅ Luby coloring\n"]},{"cell_type":"markdown","source":["↘️ **SOL...**"],"metadata":{"id":"PKybfk9M7qkg"}},{"cell_type":"code","metadata":{"id":"-Y52R0d3CA50"},"source":["%%cuda_group_save --name \"luby.cu\" --group \"lab10\"\n","#include <iostream>\n","#include \"coloring.h\"\n","\n","#define BLOCK 128\n","\n","using namespace std;\n","\n","/**\n"," * find an IS\n"," */\n","__global__ void findIS (Coloring* col, GraphStruct *str, uint* weights) {\n","\tuint idx = threadIdx.x + blockDim.x * blockIdx.x;\n","\n","\tif (idx >= str->nodeSize)\n","\t\treturn;\n","\n","\tif (col->coloring[idx])\n","\t\treturn;\n","\n","\tuint offset = str->cumDegs[idx];\n","\tuint deg = str->cumDegs[idx + 1] - str->cumDegs[idx];\n","\n","\tbool candidate = true;\n","\tfor (uint j = 0; j < deg; j++) {\n","\t\tuint neighID = str->neighs[offset + j];\n","\t\tif (!col->coloring[neighID] &&\n","\t\t\t\t((weights[idx] < weights[neighID]) ||\n","\t\t\t\t((weights[idx] == weights[neighID]) && idx < neighID))) {\n","\t\t\tcandidate = false;\n","\t\t}\n","\t}\n","\tif (candidate) {\n","\t\tcol->coloring[idx] = col->numOfColors;\n","\t}\n","\telse\n","\t\tcol->uncoloredNodes = true;\n","}\n","\n","/**\n"," *  this GPU kernel takes an array of states, and an array of ints, and puts a random int into each\n"," */\n","__global__ void init (uint seed, curandState_t* states, uint* numbers, uint n) {\n","\tuint idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\tif (idx > n)\n","\t\t\treturn;\n","\tcurand_init(seed, idx, 0, &states[idx]);\n","\tnumbers[idx] = curand(&states[idx])%n*n;\n","}\n","\n","/**\n"," * Print the graph (verbose = 1 for \"verbose print\")\n"," * @param verbose print the complete graph\n"," */\n","void printColoring (Coloring* col, GraphStruct* str, bool verbose) {\n","\tnode n = str->nodeSize;\n","\tcout << \"** Graph (num node: \" << n << \", num edges: \" << str->edgeSize << \")\" << endl;\n","\tcout << \"** Coloring (num colors: \" << col->numOfColors << \")\" << endl;\n","\tif (verbose) {\n","\t\tfor (int i = 1; i <= col->numOfColors; i++) {\n","\t\t\tcout << \"   color(\" << i << \")\" << \"-> \";\n","\t\t\tfor (int j = 0; j < n; j++)\n","\t\t\t\tif (col->coloring[j] == i)\n","\t\t\t\t\tcout << j << \" \";\n","\t\t\tcout << \"\\n\";\n","\t\t}\n","\t\tcout << \"\\n\";\n","\t}\n","}\n","\n","/**\n","* MAIN\n"," */\n","int main(void) {\n","\tunsigned int n = 1000;\t\t // number of nodes for random graphs\n","\tfloat prob = .5;\t\t\t\t    // density (percentage) for random graphs\n","\tstd::default_random_engine eng{0};  // fixed seed\n","\n","\t// new graph with n nodes\n","\tGraph graph(n,1);\n","\n","\t// generate a random graph\n","\tgraph.randGraph(prob,eng);\n","\n","\t// get the graph struct\n","\tGraphStruct *str = graph.getStruct();\n","   cout << \"** Graph (num node: \" << n << \", num edges: \" << str->edgeSize << \")\" << endl;\n","\n","\t// print small graph\n","\tif (n <= 20) {\n","\t\tgraph.print(true);  // CPU print\n","\t\tprint_d<<< 1, 1 >>>(str, true);  // GPU print\n","\t}\n","\n","   Coloring* col;\n","\tCHECK(cudaMallocManaged(&col, sizeof(Coloring)));\n","\tcol->uncoloredNodes = true;\n","\n","\t// cudaMalloc for arrays of struct Coloring\n","\tCHECK(cudaMallocManaged( &(col->coloring), n * sizeof(uint)));\n","\tmemset(col->coloring,0,n);\n","\n","\t// allocate space on the GPU for the random states\n","\tcurandState_t* states;\n","\tuint* weigths;\n","\tcudaMalloc((void**) &states, n * sizeof(curandState_t));\n","\tcudaMalloc((void**) &weigths, n * sizeof(uint));\n","\tdim3 threads (BLOCK);\n","\tdim3 blocks ((str->nodeSize + threads.x - 1) / threads.x, 1, 1 );\n","\tuint seed = 0;\n","\tinit <<< blocks, threads >>> (seed, states, weigths, n);\n","\n","   // start timer for kernel execution\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\tcudaEventRecord(start);\n","\n","\t// loop on ISs covering the graph\n","\tcol->numOfColors = 0;\n","\twhile (col->uncoloredNodes) {\n","\t\tcol->uncoloredNodes = false;\n","\t\tcol->numOfColors++;\n","\t\tfindIS <<< blocks, threads >>> (col, str, weigths);\n","      cudaDeviceSynchronize();\n","\t}\n","   cudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tfloat elapsedTime = 0;\n","\tcudaEventElapsedTime(&elapsedTime, start, stop);\n","   cout << \"   elaps time: \" << elapsedTime/1000.0f << \" (sec)\" << endl;\n","\n","   // print coloring\n","\tcout << \"   num colors: \" << col->numOfColors << endl;\n","   if (n <= 20) {\n","      printColoring(col, str, 1);\n","   }\n","\n","\tcudaFree(states);\n","\tcudaFree(weigths);\n","\n","\n","\treturn EXIT_SUCCESS;\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↘️ **TODO...**"],"metadata":{"id":"YDvg4i3B71me"}},{"cell_type":"markdown","source":["TEST on Luby\n","\n","\n","Graph print layout:\n","```\n","** Graph (num node: 10, num edges: 46)\n","      (min deg: 3, max deg: 7, mean deg: 4.6, connected: 1)\n","      node(0)[5]-> 1 2 3 7 9\n","      node(1)[3]-> 0 2 9\n","      node(2)[5]-> 0 1 3 5 8\n","      node(3)[7]-> 0 2 4 5 6 7 9\n","      node(4)[5]-> 3 6 7 8 9\n","      node(5)[5]-> 2 3 6 8 9\n","      node(6)[4]-> 3 4 5 8\n","      node(7)[3]-> 0 3 4\n","      node(8)[4]-> 2 4 5 6\n","      node(9)[5]-> 0 1 3 4 5\n","```\n","\n","\n","Coloring print layout:\n","```\n","** Graph (num node: 10, num edges: 36)\n","** Coloring (num colors: 6)\n","    color(1)-> 1 3 8\n","    color(2)-> 0 6\n","    color(3)-> 4 7\n","    color(4)-> 9\n","    color(5)-> 5\n","    color(6)-> 2\n","```\n","\n","\n"],"metadata":{"id":"ADx5EW0ZfUfO"}},{"cell_type":"code","metadata":{"id":"NnBJHLva76of"},"source":["%%cuda_group_save --name \"luby.cu\" --group \"lab10\"\n","#include <iostream>\n","#include \"coloring.h\"\n","\n","#define BLOCK 128\n","\n","using namespace std;\n","\n","/**\n"," * find an IS\n"," */\n","__global__ void findIS (Coloring* col, GraphStruct *str, uint* weights) {\n","\n","\t// TODO\n","\n","}\n","\n","/**\n"," *  this GPU kernel takes an array of states, and an array of ints, and puts a random int into each\n"," */\n","__global__ void init (uint seed, curandState_t* states, uint* numbers, uint n) {\n","\tuint idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\tif (idx > n)\n","\t\t\treturn;\n","\tcurand_init(seed, idx, 0, &states[idx]);\n","\tnumbers[idx] = curand(&states[idx])%n*n;\n","}\n","\n","/**\n"," * Print the graph (verbose = 1 for \"verbose print\")\n"," * @param verbose print the complete graph\n"," */\n","void printColoring (Coloring* col, GraphStruct* str, bool verbose) {\n","\tnode n = str->nodeSize;\n","\tcout << \"** Graph (num node: \" << n << \", num edges: \" << str->edgeSize << \")\" << endl;\n","\tcout << \"** Coloring (num colors: \" << col->numOfColors << \")\" << endl;\n","\tif (verbose) {\n","\t\tfor (int i = 1; i <= col->numOfColors; i++) {\n","\t\t\tcout << \"   color(\" << i << \")\" << \"-> \";\n","\t\t\tfor (int j = 0; j < n; j++)\n","\t\t\t\tif (col->coloring[j] == i)\n","\t\t\t\t\tcout << j << \" \";\n","\t\t\tcout << \"\\n\";\n","\t\t}\n","\t\tcout << \"\\n\";\n","\t}\n","}\n","\n","/**\n","* MAIN\n"," */\n","int main(void) {\n","\tunsigned int n = 1000;\t\t // number of nodes for random graphs\n","\tfloat prob = .5;\t\t\t\t    // density (percentage) for random graphs\n","\tstd::default_random_engine eng{0};  // fixed seed\n","\n","\t// new graph with n nodes\n","\tGraph graph(n,1);\n","\n","\t// generate a random graph\n","\tgraph.randGraph(prob,eng);\n","\n","\t// get the graph struct\n","\tGraphStruct *str = graph.getStruct();\n","   cout << \"** Graph (num node: \" << n << \", num edges: \" << str->edgeSize << \")\" << endl;\n","\n","\t// print small graph\n","\tif (n <= 20) {\n","\t\tgraph.print(true);  // CPU print\n","\t\tprint_d<<< 1, 1 >>>(str, true);  // GPU print\n","\t}\n","\n","   Coloring* col;\n","\tCHECK(cudaMallocManaged(&col, sizeof(Coloring)));\n","\tcol->uncoloredNodes = true;\n","\n","\t// cudaMalloc for arrays of struct Coloring\n","\tCHECK(cudaMallocManaged( &(col->coloring), n * sizeof(uint)));\n","\tmemset(col->coloring,0,n);\n","\n","\t// allocate space on the GPU for the random states\n","\tcurandState_t* states;\n","\tuint* weigths;\n","\tcudaMalloc((void**) &states, n * sizeof(curandState_t));\n","\tcudaMalloc((void**) &weigths, n * sizeof(uint));\n","\tdim3 threads (BLOCK);\n","\tdim3 blocks ((str->nodeSize + threads.x - 1) / threads.x, 1, 1 );\n","\tuint seed = 0;\n","\tinit <<< blocks, threads >>> (seed, states, weigths, n);\n","\n","   // start timer for kernel execution\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\tcudaEventRecord(start);\n","\n","\t// loop on ISs covering the graph\n","\n","\n","\t// TODO\n","\n","  cudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tfloat elapsedTime = 0;\n","\tcudaEventElapsedTime(&elapsedTime, start, stop);\n","   cout << \"   elaps time: \" << elapsedTime/1000.0f << \" (sec)\" << endl;\n","\n","  // print coloring\n","\tcout << \"   num colors: \" << col->numOfColors << endl;\n","   if (n <= 20) {\n","      printColoring(col, str, 1);\n","   }\n","\n","\tcudaFree(states);\n","\tcudaFree(weigths);\n","\n","\n","\treturn EXIT_SUCCESS;\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"fL5TMcJI8TTe"}},{"cell_type":"code","metadata":{"id":"0PSc9B9PDTWt"},"source":["!nvcc -arch=sm_75 src/lab10/luby.cu -o luby -I GPUcomputing/lab10 GPUcomputing/utils/graph/graph.cpp GPUcomputing/utils/graph/graph_d.cu\n","!./luby"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ✅ MergeSort"],"metadata":{"id":"VjCsAmtSffwB"}},{"cell_type":"markdown","source":["↘️ **SOL...**"],"metadata":{"id":"Gaxf95tLivur"}},{"cell_type":"code","source":["%%cuda_group_save --name \"merge_sort.cu\" --group \"lab10\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include <time.h>\n","#include \"../../GPUcomputing/utils/common.h\"\n","\n","#define ARRAY_SIZE 64\n","\n","void check_up_sorting(int *, unsigned);\n","void random_array(int *, unsigned, int);\n","void printArray(int *, int, int);\n","void mergeSort(int *, int, int);\n","void merge(int *, int, int, int);\n","void arrayCopy(int *, const int *, const int);\n","\n","/**\n"," * Kernel: mergeSort with seq. merge\n"," */\n","__global__ void cudaMergeSort(int *array, int *sorted, int n, int chunk) {\n","\n","\tint start = chunk * (threadIdx.x + blockIdx.x * blockDim.x);\n","\tif (start > n - chunk)\n","\t\treturn;\n","\n","\tint mid = start + chunk / 2;\n","\tint end = start + chunk;\n","\tint i = start, j = mid, k = start;\n","\n","\t// cudaMerge(array, sorted, start, mid, end);\n","\twhile (i < mid && j < end)\n","\t\tif (array[i] <= array[j])\n","\t\t\tsorted[k++] = array[i++];\n","\t\telse\n","\t\t\tsorted[k++] = array[j++];\n","\n","\t//  Copy the remaining elements array[i] if there are any\n","\twhile (i < mid)\n","\t\tsorted[k++] = array[i++];\n","\n","\t// Copy the remaining elements of array[j] if there are any\n","\twhile (j < end)\n","\t\tsorted[k++] = array[j++];\n","}\n","\n","/**\n"," * A iterative binary search function. It returns the location p of\n"," * the first element in r-length arr[0..r-1] greater than x\n"," */\n","__device__ int binarySearch(int arr[], int x, int k, bool UP) {\n","\tint l = 0, r = k;\n","\n","\twhile (l < r) {\n","\t\tint m = (l+r)/2;\n","\t\tif (UP) {     //# for upper chunk B\n","\t\t\tif (arr[m] <= x) l = m + 1;\n","\t\t\telse r = m;\n","\t\t}\n","\t\telse {       //# for lower chunk A\n","\t\t\tif (arr[m] < x) l = m + 1;\n","\t\t\telse r = m;\n","\t\t}\n","\t}\n","\treturn l;\n","}\n","\n","/**\n"," * Kernel: mergeSort with many threads. Each thread deals with 2 elements:\n"," *  A[i] in first chunk and the corresponding B[i] in the second chunk\n"," */\n","__global__ void cudaMergeSortMulti(int *array, int *sorted, int n, int k) {\n","\t// k = 2,4,8,16,..., 2^m chunk dims\n","\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n","\tint j = tid % k;\n","\tint l = (tid - j)*2;  // first element of the first chunk\n","\tint i = l + j;        // A[i] first chunk   [][][*][] and  B[i+k] [][][*][]\n","\n","\tif (k == 1) {\n","\t\tl = 2*tid;\n","\t\ti = l;\n","\t}\n","\n","\t//# find the relative position of x within B[*]\n","\tint x = array[i];\n","\tint p = binarySearch(array+l+k, x, k, 1);\n","\tsorted[i+p] = x;\n","\n","\t//# find the relative position of y within A[*]\n","\tint y = array[i+k];\n","\tp = binarySearch(array+l, y, k, 0);\n","\tsorted[i+p] = y;\n","}\n","\n","/*\n"," * MAIN\n"," */\n","int main(int argc, char** argv) {\n","\n","\t// Create the vector with the specified size and situation\n","\tint *orig, *array, *sorted;\n","\tint N = 4*1024*1024;         // must be a power of 2\n","\tint BLOCK_SIZE = 32;\n","\n","\tprintf(\"Sorting array size N = %d\\n\",N);\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// managed memory\n","\tCHECK(cudaMallocManaged((void **)&array, N * sizeof(int)));\n","\tCHECK(cudaMallocManaged((void **)&sorted, N * sizeof(int)));\n","\n","\t// random instance\n","\torig = (int *) malloc(N * sizeof(int));\n","\trandom_array(orig, N, 1);\n","\tarrayCopy(array, orig, N);\n","\t// printArray(array,N,16);\n","\n","\t/*****************************************************\n","\t *                      CPU                          *\n","\t *****************************************************/\n","\n","  printf(\"** CPU processing...\\n\");\n","\tdouble startTm = seconds();\n","\tmergeSort(array, 0, N);\n","\tdouble CPUtime = seconds() - startTm;\n","\tprintf(\"   CPU elapsed time: %.5f (sec)\\n\", CPUtime);\n","\tcheck_up_sorting(array, N);\n","\n","\t/*****************************************************\n","\t *              ONE THREAD x chunk                   *\n","\t *****************************************************/\n","\n","  printf(\"\\n** GPU ONE THREAD x chunk processing...\\n\");\n","\tarrayCopy(sorted, orig, N); // start from step 2\n","\tbool array2sorted = false;\n","\tCHECK(cudaEventRecord(start));\n","\tfor (int chunk = 2; chunk <= N; chunk *= 2) {\n","\t\tint nThreads = N / chunk;\n","\t\tdim3 block(min(nThreads, BLOCK_SIZE));\n","\t\tdim3 grid((nThreads + block.x - 1) / block.x);\n","\n","\t\tif (array2sorted)\n","\t\t\tcudaMergeSort<<<grid, block>>>(array, sorted, N, chunk);\n","\t\telse\n","\t\t\tcudaMergeSort<<<grid, block>>>(sorted, array, N, chunk);\n","\t\tarray2sorted = !array2sorted;\n","\t}\n","\tCHECK(cudaDeviceSynchronize());\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tfloat milliseconds;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tfloat GPUtime = milliseconds / 1000.0;\n","\tprintf(\"   elapsed time:   %.5f (sec)\\n\", GPUtime);\n","\tprintf(\"   speedup vs CPU: %.2f\\n\", CPUtime / GPUtime);\n","\n","\tcheck_up_sorting(sorted, N);\n","\n","\t/*****************************************************\n","\t *              MULTI THREAD x chunk                 *\n","\t *****************************************************/\n","\tprintf(\"\\n** GPU MULTI THREAD x chunk processing...\\n\");\n","\tarrayCopy(array, orig, N);\n","\tarray2sorted = false;\n","\n","\t// grid set up\n","\tint nThreads = N/2;\n","\tdim3 block(min(nThreads, BLOCK_SIZE));\n","\tdim3 grid((nThreads + block.x - 1) / block.x);\n","\tCHECK(cudaEventRecord(start));\n","\tfor (int chunk = 1; chunk <= N/2; chunk *= 2) {\n","\t\tarray2sorted = !array2sorted;\n","\t\tif (array2sorted)\n","\t\t\tcudaMergeSortMulti<<<grid, block>>>(array, sorted, N, chunk);\n","\t\telse\n","\t\t\tcudaMergeSortMulti<<<grid, block>>>(sorted, array, N, chunk);\n","\t}\n","\tCHECK(cudaDeviceSynchronize());\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tfloat GPUtime1 = milliseconds / 1000.0;\n","\tprintf(\"   elapsed time:        %.5f (sec)\\n\", GPUtime1);\n","\tprintf(\"   speedup vs CPU:      %.2f\\n\", CPUtime / GPUtime1);\n","\tprintf(\"   speedup vs GPU mono: %.2f\\n\", GPUtime / GPUtime1);\n","\tif (!array2sorted) {\n","\t\tint *swap = sorted;\n","\t\tsorted = array;\n","\t\tarray = swap;\n","\t}\n","\tcheck_up_sorting(sorted, N);\n","\n","//\tprintArray(array,N,32);\n","//\tprintArray(sorted,N,64);\n","\n","\treturn 0;\n","}"],"metadata":{"id":"yvuYS43JdWov"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↘️ **TODO...**"],"metadata":{"id":"RoDs9gZd9Wna"}},{"cell_type":"code","source":["%%cuda_group_save --name \"merge_sort.cu\" --group \"lab10\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include <time.h>\n","#include \"../../GPUcomputing/utils/common.h\"\n","\n","#define ARRAY_SIZE 64\n","\n","void check_up_sorting(int *, unsigned);\n","void random_array(int *, unsigned, int);\n","void printArray(int *, int, int);\n","void mergeSort(int *, int, int);\n","void merge(int *, int, int, int);\n","void arrayCopy(int *, const int *, const int);\n","\n","/**\n"," * Kernel: mergeSort with seq. merge\n"," */\n","__global__ void cudaMergeSort(int *array, int *sorted, int n, int chunk) {\n","\n","\tint start = chunk * (threadIdx.x + blockIdx.x * blockDim.x);\n","\tif (start > n - chunk)\n","\t\treturn;\n","\n","\tint mid = start + chunk / 2;\n","\tint end = start + chunk;\n","\tint i = start, j = mid, k = start;\n","\n","\t// cudaMerge(array, sorted, start, mid, end);\n","\twhile (i < mid && j < end)\n","\t\tif (array[i] <= array[j])\n","\t\t\tsorted[k++] = array[i++];\n","\t\telse\n","\t\t\tsorted[k++] = array[j++];\n","\n","\t//  Copy the remaining elements array[i] if there are any\n","\twhile (i < mid)\n","\t\tsorted[k++] = array[i++];\n","\n","\t// Copy the remaining elements of array[j] if there are any\n","\twhile (j < end)\n","\t\tsorted[k++] = array[j++];\n","}\n","\n","/**\n"," * A iterative binary search function. It returns the location p of\n"," * the first element in r-length arr[0..r-1] greater than x\n"," */\n","__device__ int binarySearch(int arr[], int x, int k, bool UP) {\n","\tint l = 0, r = k;\n","\n","\twhile (l < r) {\n","\t\tint m = (l+r)/2;\n","\t\tif (UP) {     //# for upper chunk B\n","\t\t\tif (arr[m] <= x) l = m + 1;\n","\t\t\telse r = m;\n","\t\t}\n","\t\telse {       //# for lower chunk A\n","\t\t\tif (arr[m] < x) l = m + 1;\n","\t\t\telse r = m;\n","\t\t}\n","\t}\n","\treturn l;\n","}\n","\n","/**\n"," * Kernel: mergeSort with many threads. Each thread deals with 2 elements:\n"," *  A[i] in first chunk and the corresponding B[i] in the second chunk\n"," */\n","__global__ void cudaMergeSortMulti(int *array, int *sorted, int n, int k) {\n","\n","\t// TODO\n","\n"," }\n","\n","/*\n"," * MAIN\n"," */\n","int main(int argc, char** argv) {\n","\n","\t// Create the vector with the specified size and situation\n","\tint *orig, *array, *sorted;\n","\tint N = 4*1024*1024;         // must be a power of 2\n","\tint BLOCK_SIZE = 32;\n","\n","\tprintf(\"Sorting array size N = %d\\n\",N);\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// managed memory\n","\tCHECK(cudaMallocManaged((void **)&array, N * sizeof(int)));\n","\tCHECK(cudaMallocManaged((void **)&sorted, N * sizeof(int)));\n","\n","\t// random instance\n","\torig = (int *) malloc(N * sizeof(int));\n","\trandom_array(orig, N, 1);\n","\tarrayCopy(array, orig, N);\n","\t// printArray(array,N,16);\n","\n","\t/*****************************************************\n","\t *                      CPU                          *\n","\t *****************************************************/\n","\n","  printf(\"** CPU processing...\\n\");\n","\tdouble startTm = seconds();\n","\tmergeSort(array, 0, N);\n","\tdouble CPUtime = seconds() - startTm;\n","\tprintf(\"   CPU elapsed time: %.5f (sec)\\n\", CPUtime);\n","\tcheck_up_sorting(array, N);\n","\n","\t/*****************************************************\n","\t *              ONE THREAD x chunk                   *\n","\t *****************************************************/\n","\n","  printf(\"\\n** GPU ONE THREAD x chunk processing...\\n\");\n","\tarrayCopy(sorted, orig, N); // start from step 2\n","\tbool array2sorted = false;\n","\tCHECK(cudaEventRecord(start));\n","\tfor (int chunk = 2; chunk <= N; chunk *= 2) {\n","\t\tint nThreads = N / chunk;\n","\t\tdim3 block(min(nThreads, BLOCK_SIZE));\n","\t\tdim3 grid((nThreads + block.x - 1) / block.x);\n","\n","\t\tif (array2sorted)\n","\t\t\tcudaMergeSort<<<grid, block>>>(array, sorted, N, chunk);\n","\t\telse\n","\t\t\tcudaMergeSort<<<grid, block>>>(sorted, array, N, chunk);\n","\t\tarray2sorted = !array2sorted;\n","\t}\n","\tCHECK(cudaDeviceSynchronize());\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tfloat milliseconds;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tfloat GPUtime = milliseconds / 1000.0;\n","\tprintf(\"   elapsed time:   %.5f (sec)\\n\", GPUtime);\n","\tprintf(\"   speedup vs CPU: %.2f\\n\", CPUtime / GPUtime);\n","\n","\tcheck_up_sorting(sorted, N);\n","\n","\t/*****************************************************\n","\t *              MULTI THREAD x chunk                 *\n","\t *****************************************************/\n","\tprintf(\"\\n** GPU MULTI THREAD x chunk processing...\\n\");\n","\tarrayCopy(array, orig, N);\n","\tarray2sorted = false;\n","\n","\t// grid set up\n","\tint nThreads = N/2;\n","\tdim3 block(min(nThreads, BLOCK_SIZE));\n","\tdim3 grid((nThreads + block.x - 1) / block.x);\n","\tCHECK(cudaEventRecord(start));\n","\n","\t\t// TODO\n","\n","\tCHECK(cudaDeviceSynchronize());\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tfloat GPUtime1 = milliseconds / 1000.0;\n","\tprintf(\"   elapsed time:        %.5f (sec)\\n\", GPUtime1);\n","\tprintf(\"   speedup vs CPU:      %.2f\\n\", CPUtime / GPUtime1);\n","\tprintf(\"   speedup vs GPU mono: %.2f\\n\", GPUtime / GPUtime1);\n","\tif (!array2sorted) {\n","\t\tint *swap = sorted;\n","\t\tsorted = array;\n","\t\tarray = swap;\n","\t}\n","\tcheck_up_sorting(sorted, N);\n","\n","//\tprintArray(array,N,32);\n","//\tprintArray(sorted,N,64);\n","\n","\treturn 0;\n","}"],"metadata":{"id":"a5lf4AFrs3QW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"Pv4zXce_krNG"}},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/lab10/merge_sort.cu GPUcomputing/utils/merge_sort_CPU.cpp -o mergesort\n","!./mergesort"],"metadata":{"id":"Pc9wyH8_fdia"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ✅ BitonicSort"],"metadata":{"id":"Y3--q4d2WgYC"}},{"cell_type":"markdown","source":["↘️ **SOL...**"],"metadata":{"id":"r8SXG6og_0Or"}},{"cell_type":"markdown","source":["\n"," * Gli indici $k$ e $j$ in input hanno significato:\n","   * $k = 2,4,8,...,2^s=N$\n","   * $j = 2^{(k-1)}, 2^{(k-2)},...,1$ (parte dalla metà di k e continua a dimezzare)\n"," * Gli operatori sui bit ^ (XOR) e & (AND) vengono usati per filtrare i thread:\n","   * $ixj = i^j$  aggiunge o toglie a $i$ una potenza di 2, cioé $ixj = i \\pm j$ con $j = 2^a$\n","   * $i \\& k == 0$ vero sse $i \\le k$ (sort ascendente) altrimenti sort discendente\n"," * L'operazione $ixj > i$ significa aggiorna solo quando l'indice $ixj$ fa un salto in avanti di $j=2^a$\n"],"metadata":{"id":"ZvFwovXxbkCg"}},{"cell_type":"code","source":["%%cuda_group_save --name \"bitonic.cu\" --group \"lab10\"\n","\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include <time.h>\n","\n","#include \"../../GPUcomputing/utils/common.h\"\n","\n","#define THREADS 1024\n","#define BLOCKS 16*1024\n","\n","__global__ void bitonic_sort_step(int *a, int j, int k) {\n","\tunsigned int i, ixj;      // Sorting partners i and ixj\n","\ti = threadIdx.x + blockDim.x * blockIdx.x;\n","\tixj = i ^ j;              // XOR: aggiunge o toglie a i una potenza di 2, j = 2^a\n","\n","  #ifdef DEBUG\n","\tif (i == 0)\n","\t\tprintf(\"ROUND: k = %d, j = %d\\n\", k, j);\n","  #endif\n","\n","\tif ((ixj) > i) {    // entra solo quando fa un salto di j = 2^a\n","\n","    // Sort ascending\n","\t\tif ((i & k) == 0) {\n","      #ifdef DEBUG\n","\t\t\tprintf(\"  UP  (ixj = %d\\t    i = %d\\t k = %d)   a[ixj] = %d - a[i] = %d\\n\", ixj, i, k, a[ixj],a[i]);\n","      #endif\n","\t\t\tif (a[i] > a[ixj]) {\n","\t\t\t\tint temp = a[i];\n","\t\t\t\ta[i] = a[ixj];\n","\t\t\t\ta[ixj] = temp;\n","\t\t\t}\n","\t\t}\n","\n","\t\t// Sort descending\n","\t\tif ((i & k) != 0) {\n","      #ifdef DEBUG\n","\t\t\tprintf(\"  DOWN  (ixj = %d\\t    i = %d\\t k = %d)   a[ixj] = %d - a[i] = %d\\n\", ixj, i, k, a[ixj],a[i]);\n","      #endif\n","\t\t\tif (a[i] < a[ixj]) {\n","\t\t\t\tint temp = a[i];\n","\t\t\t\ta[i] = a[ixj];\n","\t\t\t\ta[ixj] = temp;\n","\t\t\t}\n","\t\t}\n","\t}\n","}\n","\n","/*The parameter dir indicates the sorting direction, ASCENDING\n"," or DESCENDING; if (a[i] > a[j]) agrees with the direction,\n"," then a[i] and a[j] are interchanged.*/\n","void compAndSwap(int a[], int i, int j, int dir) {\n","\tif (dir == (a[i] > a[j])) {\n","\t\tint tmp = a[i];\n","\t\ta[i] = a[j];\n","\t\ta[j] = tmp;\n","\t}\n","}\n","\n","/*It recursively sorts a bitonic sequence in ascending order,\n"," if dir = 1, and in descending order otherwise (means dir=0).\n"," The sequence to be sorted starts at index position low,\n"," the parameter cnt is the number of elements to be sorted.*/\n","void bitonicMerge(int a[], int low, int cnt, int dir) {\n","\tif (cnt > 1) {\n","\t\tint k = cnt / 2;\n","\t\tfor (int i = low; i < low + k; i++)\n","\t\t\tcompAndSwap(a, i, i + k, dir);\n","\t\tbitonicMerge(a, low, k, dir);\n","\t\tbitonicMerge(a, low + k, k, dir);\n","\t}\n","}\n","\n","/* This function first produces a bitonic sequence by recursively\n"," sorting its two halves in opposite sorting orders, and then\n"," calls bitonicMerge to make them in the same order */\n","void bitonicSort(int a[], int low, int cnt, int dir) {\n","\tif (cnt > 1) {\n","\t\tint k = cnt / 2;\n","\n","\t\t// sort in ascending order since dir here is 1\n","\t\tbitonicSort(a, low, k, 1);\n","\n","\t\t// sort in descending order since dir here is 0\n","\t\tbitonicSort(a, low + k, k, 0);\n","\n","\t\t// Will merge wole sequence in ascending order\n","\t\t// since dir=1.\n","\t\tbitonicMerge(a, low, cnt, dir);\n","\t}\n","}\n","\n","/*\n"," * MAIN: test bitonic sort on CPU and GPU\n"," */\n","int main(void) {\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\tint N = THREADS*BLOCKS;\n","\t// check\n","\tif (!(N && !(N & (N - 1)))) {\n","\t\tprintf(\"ERROR: N must be power of 2 (N = %d)\\n\", N);\n","\t\texit(1);\n","\t}\n","\tsize_t nBytes = N * sizeof(int);\n","\tint *a = (int*) malloc(nBytes);\n","\tint *b = (int*) malloc(nBytes);\n","\n","\t// fill data\n","\tfor (int i = 0; i < N; ++i) {\n","\t\ta[i] =  rand() % 100;\n","\t\tb[i] = a[i];\n","\t}\n","\n","\t// bitonic CPU\n","\tdouble cpu_time = seconds();\n","\tbitonicSort(b, 0, N, 1);   // 1 means sort in ascending order\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\", seconds()-cpu_time);\n","\n","\t// device mem copy\n","\tint *d_a;\n","\tCHECK(cudaMalloc((void**) &d_a, nBytes));\n","\tCHECK(cudaMemcpy(d_a, a, nBytes, cudaMemcpyHostToDevice));\n","\n","\t// num of threads\n","\tdim3 blocks(BLOCKS, 1);   // Number of blocks\n","\tdim3 threads(THREADS, 1); // Number of threads\n","\n","\t// start computation\n","\tcudaEventRecord(start);\n","\tint j, k;\n","\t// external loop on comparators of size k\n","\tfor (k = 2; k <= N; k <<= 1) {\n","\t\t// internal loop for comparator internal stages\n","\t\tfor (j = k >> 1; j > 0; j = j >> 1)\n","\t\t\tbitonic_sort_step<<<blocks, threads>>>(d_a, j, k);\n","\t}\n","\tcudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tfloat milliseconds = 0;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tprintf(\"GPU elapsed time: %.5f (sec)\\n\", milliseconds / 1000);\n","\n","\t// recover data\n","\tcudaMemcpy(a, d_a, nBytes, cudaMemcpyDeviceToHost);\n","\n","\t// print & check\n","\tif (N < 100) {\n","\t\tprintf(\"GPU:\\n\");\n","\t\tfor (int i = 0; i < N; ++i)\n","\t\t\tprintf(\"%d  \", a[i]);\n","\t\tprintf(\"\\nCPU:\\n\");\n","\t\tfor (int i = 0; i < N; ++i)\n","\t\t\tprintf(\"%d  \", b[i]);\n","\t}\n","\telse {\n","\t\tfor (int i = 0; i < N; ++i) {\n","\t\t\tif (a[i] != b[i]) {\n","\t\t\t\tprintf(\"ERROR a[%d] != b[%d]  (a[i] = %d  -  b[i] = %d\\n\", i,i, a[i],b[i]);\n","\t\t\t\tbreak;\n","\t\t\t}\n","\t\t}\n","\t}\n","\n","\tcudaFree(d_a);\n","\texit(0);\n","}"],"metadata":{"id":"H2gYxIR1WkeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↘️ **TODO...**"],"metadata":{"id":"R0JV7ojS_erB"}},{"cell_type":"code","source":["%%cuda_group_save --name \"bitonic.cu\" --group \"lab10\"\n","\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include <time.h>\n","\n","#include \"../../GPUcomputing/utils/common.h\"\n","\n","#define THREADS 1024\n","#define BLOCKS 16*1024\n","\n","__global__ void bitonic_sort_step(int *a, int j, int k) {\n","\n","\t// TODO\n","\n","}\n","\n","/*The parameter dir indicates the sorting direction, ASCENDING\n"," or DESCENDING; if (a[i] > a[j]) agrees with the direction,\n"," then a[i] and a[j] are interchanged.*/\n","void compAndSwap(int a[], int i, int j, int dir) {\n","\tif (dir == (a[i] > a[j])) {\n","\t\tint tmp = a[i];\n","\t\ta[i] = a[j];\n","\t\ta[j] = tmp;\n","\t}\n","}\n","\n","/*It recursively sorts a bitonic sequence in ascending order,\n"," if dir = 1, and in descending order otherwise (means dir=0).\n"," The sequence to be sorted starts at index position low,\n"," the parameter cnt is the number of elements to be sorted.*/\n","void bitonicMerge(int a[], int low, int cnt, int dir) {\n","\tif (cnt > 1) {\n","\t\tint k = cnt / 2;\n","\t\tfor (int i = low; i < low + k; i++)\n","\t\t\tcompAndSwap(a, i, i + k, dir);\n","\t\tbitonicMerge(a, low, k, dir);\n","\t\tbitonicMerge(a, low + k, k, dir);\n","\t}\n","}\n","\n","/* This function first produces a bitonic sequence by recursively\n"," sorting its two halves in opposite sorting orders, and then\n"," calls bitonicMerge to make them in the same order */\n","void bitonicSort(int a[], int low, int cnt, int dir) {\n","\tif (cnt > 1) {\n","\t\tint k = cnt / 2;\n","\n","\t\t// sort in ascending order since dir here is 1\n","\t\tbitonicSort(a, low, k, 1);\n","\n","\t\t// sort in descending order since dir here is 0\n","\t\tbitonicSort(a, low + k, k, 0);\n","\n","\t\t// Will merge wole sequence in ascending order\n","\t\t// since dir=1.\n","\t\tbitonicMerge(a, low, cnt, dir);\n","\t}\n","}\n","\n","/*\n"," * MAIN: test bitonic sort on CPU and GPU\n"," */\n","int main(void) {\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\tint N = THREADS*BLOCKS;\n","\t// check\n","\tif (!(N && !(N & (N - 1)))) {\n","\t\tprintf(\"ERROR: N must be power of 2 (N = %d)\\n\", N);\n","\t\texit(1);\n","\t}\n","\tsize_t nBytes = N * sizeof(int);\n","\tint *a = (int*) malloc(nBytes);\n","\tint *b = (int*) malloc(nBytes);\n","\n","\t// fill data\n","\tfor (int i = 0; i < N; ++i) {\n","\t\ta[i] =  rand() % 100;\n","\t\tb[i] = a[i];\n","\t}\n","\n","\t// bitonic CPU\n","\tdouble cpu_time = seconds();\n","\tbitonicSort(b, 0, N, 1);   // 1 means sort in ascending order\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\", seconds()-cpu_time);\n","\n","\t// device mem copy\n","\tint *d_a;\n","\tCHECK(cudaMalloc((void**) &d_a, nBytes));\n","\tCHECK(cudaMemcpy(d_a, a, nBytes, cudaMemcpyHostToDevice));\n","\n","\t// num of threads\n","\tdim3 blocks(BLOCKS, 1);   // Number of blocks\n","\tdim3 threads(THREADS, 1); // Number of threads\n","\n","\t// start computation on GPU\n","\tcudaEventRecord(start);\n","\tint j, k;\n","\n","\t  // TODO\n","\n","\tcudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tfloat milliseconds = 0;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tprintf(\"GPU elapsed time: %.5f (sec)\\n\", milliseconds / 1000);\n","\n","\t// recover data\n","\tcudaMemcpy(a, d_a, nBytes, cudaMemcpyDeviceToHost);\n","\n","\t// print & check\n","\tif (N < 100) {\n","\t\tprintf(\"GPU:\\n\");\n","\t\tfor (int i = 0; i < N; ++i)\n","\t\t\tprintf(\"%d  \", a[i]);\n","\t\tprintf(\"\\nCPU:\\n\");\n","\t\tfor (int i = 0; i < N; ++i)\n","\t\t\tprintf(\"%d  \", b[i]);\n","\t}\n","\telse {\n","\t\tfor (int i = 0; i < N; ++i) {\n","\t\t\tif (a[i] != b[i]) {\n","\t\t\t\tprintf(\"ERROR a[%d] != b[%d]  (a[i] = %d  -  b[i] = %d\\n\", i,i, a[i],b[i]);\n","\t\t\t\tbreak;\n","\t\t\t}\n","\t\t}\n","\t}\n","\n","\tcudaFree(d_a);\n","\texit(0);\n","}"],"metadata":{"id":"EVYjyoaA_YuF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["↩ **Run...**"],"metadata":{"id":"LceXknvy_Tpm"}},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/lab10/bitonic.cu -o bitonic\n","!./bitonic"],"metadata":{"id":"6kQqaEB9W3Nd"},"execution_count":null,"outputs":[]}]}